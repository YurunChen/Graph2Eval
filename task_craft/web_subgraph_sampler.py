"""
Web Subgraph Sampler - å­å›¾é€‰æ‹©ç­–ç•¥ - ä¿®å¤ç‰ˆæœ¬
FIXED ISSUES:
1. ç®€åŒ–å¹¶å‘è®¾è®¡ - åªä¿ç•™ç§å­çº§å¹¶å‘ï¼Œé¿å…åµŒå¥—å¹¶å‘é—®é¢˜
2. ä½¿ç”¨çº¿ç¨‹æ±  - é¿å…åºåˆ—åŒ–é—®é¢˜ï¼Œæé«˜æ€§èƒ½
3. ä¼˜åŒ–å‚æ•° - è°ƒæ•´workeræ•°é‡å’Œchunkå¤§å°
4. åˆ é™¤å¤æ‚åµŒå¥—å¹¶å‘ - ç§»é™¤å¯¼è‡´æ€§èƒ½é—®é¢˜çš„ä»£ç 

æŒ‰ç­–ç•¥å–r-hopå­å›¾ï¼Œæ§é•¿ã€æ§å™ªã€æ§å¤æ‚åº¦ï¼Œç¡®ä¿ä»»åŠ¡ä¸å®é™…UIç»“æ„å¼ºç»‘å®š
æ”¯æŒç®€åŒ–çš„å¹¶å‘å¤„ç†ä»¥æé«˜é‡‡æ ·æ•ˆç‡
"""

import logging
import random
import time
from typing import Dict, List, Any, Optional, Set, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import json
import os
from pathlib import Path

# New: concurrent processing related imports
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from threading import Lock

# Try to import psutil, provide default value if not available
try:
    import psutil
except ImportError:
    psutil = None
    logger.warning("ğŸ¯ psutil not available, using default memory values")

from loguru import logger
from collections import defaultdict, deque
from graph_rag.graph_builder import TaskGraph
from graph_rag.edge_types import GraphEdge, EdgeType
from graph_rag.node_types import GraphNode, NodeType
from .task_seeds import TaskSeedPattern, TaskSeedType
from config_manager import get_config

class SamplingStrategy(Enum):
    """å­å›¾é‡‡æ ·ç­–ç•¥"""
    ELEMENT_CENTRIC = "element_centric"  # Element-centric
    RELATION_CENTRIC = "relation_centric"  # Relation-centric
    GOAL_CONDITIONED = "goal_conditioned"  # Goal-conditioned
    CURRICULUM_RADIUS = "curriculum_radius"  # Curriculum radius

    STRUCTURE_FIRST = "structure_first"  # Structure-first
    FUNCTIONAL_MODULE = "functional_module"  # Functional module-oriented

@dataclass
class SubgraphConfig:
    """å­å›¾é…ç½®"""
    strategy: SamplingStrategy = SamplingStrategy.ELEMENT_CENTRIC
    max_radius: int = 2  # Maximum hops
    min_nodes: int = 3   # Minimum number of nodes
    max_nodes: int = 15   # Maximum number of nodes
    max_subgraphs_per_seed: int = 15  # Maximum subgraphs per seed (ensure quality)
    max_total_subgraphs: int = 200  # Maximum total subgraphs (ensure diversity)
    target_task_type: Optional[str] = None  # Target task type
    curriculum_step: int = 1  # Current step in curriculum learning
    
    # Fixed concurrency configuration
    enable_concurrency: bool = True  # Whether to enable concurrency
    max_workers: int = 4  # Maximum worker threads (reduce worker count)
    chunk_size: int = 8   # Task chunk size (increase chunk size, reduce task fragmentation)
    use_thread_pool: bool = True  # Use thread pool to avoid serialization issues
    
    @classmethod
    def from_config(cls):
        """ä»é…ç½®æ–‡ä»¶åˆ›å»ºé…ç½®"""
        config = get_config()
        web_sampling_config = config.task_craft.get('web_subgraph_sampling', {})
        
        # Strategy mapping
        strategy_mapping = {
            "element_centric": SamplingStrategy.ELEMENT_CENTRIC,
            "relation_centric": SamplingStrategy.RELATION_CENTRIC,
            "goal_conditioned": SamplingStrategy.GOAL_CONDITIONED,
            "curriculum_radius": SamplingStrategy.CURRICULUM_RADIUS,
    
        }
        
        strategy_str = web_sampling_config.get('sampling_strategy', 'element_centric')
        strategy = strategy_mapping.get(strategy_str, SamplingStrategy.ELEMENT_CENTRIC)
        
        # Concurrency configuration
        concurrency_config = web_sampling_config.get('concurrency', {})
        
        return cls(
            strategy=strategy,
            max_radius=web_sampling_config.get('max_radius', 2),
            min_nodes=web_sampling_config.get('min_nodes', 3),
            max_nodes=web_sampling_config.get('max_nodes', 15),
            max_subgraphs_per_seed=web_sampling_config.get('max_subgraphs_per_seed', 15),
            max_total_subgraphs=web_sampling_config.get('max_total_subgraphs', 200),
            target_task_type=web_sampling_config.get('target_task_type'),
            curriculum_step=web_sampling_config.get('curriculum_step', 1),
            enable_concurrency=concurrency_config.get('enable', True),
            max_workers=concurrency_config.get('max_workers', min(4, os.cpu_count() or 4)),
            chunk_size=concurrency_config.get('chunk_size', 8),  # Increase default chunk size
            use_thread_pool=concurrency_config.get('use_thread_pool', True)  # Default to use thread pool
        )

@dataclass
class SubgraphSample:
    """å­å›¾æ ·æœ¬"""
    nodes: Dict[str, GraphNode] = field(default_factory=dict)
    edges: Dict[str, GraphEdge] = field(default_factory=dict)
    center_node: Optional[str] = None
    radius: int = 0
    strategy: SamplingStrategy = SamplingStrategy.ELEMENT_CENTRIC
    task_seed: Optional[TaskSeedPattern] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "nodes": {node_id: node.to_dict() for node_id, node in self.nodes.items()},
            "edges": {edge_id: edge.to_dict() for edge_id, edge in self.edges.items()},
            "center_node": self.center_node,
            "radius": self.radius,
            "strategy": self.strategy.value,
            "task_seed": self.task_seed.name if self.task_seed else None
        }

class WebSubgraphSampler:
    """Webå­å›¾é‡‡æ ·å™¨ - æ”¯æŒå¹¶å‘å¤„ç†"""
    
    def __init__(self, config: SubgraphConfig):
        self.config = config
        self._lock = threading.Lock()  # Thread safety lock
        self.executor = None
        
        # Initialize executor
        self._init_executor()
    
    def _get_node_safe(self, task_graph: TaskGraph, node_id: str) -> Optional[Any]:
        """å®‰å…¨åœ°è·å–èŠ‚ç‚¹ï¼Œé¿å…Noneé”™è¯¯"""
        node = task_graph.nodes.get(node_id)
        if node is None:
            logger.debug(f"ğŸ¯ Node {node_id} is None or not found")
        return node
    
    def _init_executor(self):
        """åˆå§‹åŒ–æ‰§è¡Œå™¨"""
        if self.config.enable_concurrency:
            if self.config.use_thread_pool:
                # Use thread pool to avoid serialization issues
                self.executor = ThreadPoolExecutor(max_workers=self.config.max_workers)
                logger.info(f"ğŸ¯ Initialized ThreadPoolExecutor with {self.config.max_workers} workers")
            else:
                # If configured not to use thread pool, disable concurrency
                self.executor = None
                logger.info("ğŸ¯ Thread pool disabled, using sequential processing")
        else:
            self.executor = None
            logger.info("ğŸ¯ Concurrency disabled, using sequential processing")
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if self.executor:
            self.executor.shutdown(wait=True)
    
# åˆ é™¤é‡å¤çš„æ–¹æ³•å®šä¹‰ï¼Œä¿ç•™ä¸‹é¢çš„æ­£ç¡®ç‰ˆæœ¬
    
    
    
    
    def _curriculum_radius_sampling(self, task_graph: TaskGraph, task_seeds: List[TaskSeedPattern]) -> List[SubgraphSample]:
        """è¯¾ç¨‹å¼åŠå¾„é‡‡æ · - é€æ­¥æ‰©å¤§åŠå¾„"""
        subgraphs = []
        
        # æ ¹æ®è¯¾ç¨‹æ­¥éª¤ç¡®å®šå½“å‰åŠå¾„
        current_radius = min(self.config.curriculum_step, self.config.max_radius)
        
        # ä»ç®€å•ä»»åŠ¡å¼€å§‹
        simple_seeds = [seed for seed in task_seeds if seed.difficulty == "EASY"]
        medium_seeds = [seed for seed in task_seeds if seed.difficulty == "MEDIUM"]
        hard_seeds = [seed for seed in task_seeds if seed.difficulty == "HARD"]
        
        seed_priority = simple_seeds + medium_seeds + hard_seeds
        
        for seed in seed_priority:
            # æ ¹æ®å½“å‰åŠå¾„é‡‡æ ·
            subgraph = self._radius_based_sampling(task_graph, seed, current_radius)
            if subgraph and self._validate_subgraph(subgraph, seed):
                subgraphs.append(subgraph)
        
        return subgraphs
    
    
    def _deduplicate_subgraphs(self, subgraphs: List[SubgraphSample]) -> List[SubgraphSample]:
        """å»é‡å­å›¾ï¼Œä¿ç•™æœ€ä¼˜è´¨çš„"""
        if not subgraphs:
            return []
        
        # æŒ‰èŠ‚ç‚¹é›†åˆå»é‡
        unique_subgraphs = []
        seen_node_sets = set()
        
        for subgraph in subgraphs:
            node_set = frozenset(subgraph.nodes.keys())
            if node_set not in seen_node_sets:
                seen_node_sets.add(node_set)
                unique_subgraphs.append(subgraph)
        
        logger.info(f"ğŸ¯ Deduplication: {len(subgraphs)} -> {len(unique_subgraphs)} subgraphs")
        return unique_subgraphs
    
    def _find_related_business_data(self, task_graph: TaskGraph, subgraph_node_ids: List[str]) -> List[str]:
        """æŸ¥æ‰¾ä¸å­å›¾ç›¸å…³çš„ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹ - ä¿®å¤ç‰ˆæœ¬"""
        related_business_data = []
        
        # è·å–å­å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„é¡µé¢URL
        subgraph_urls = set()
        for node_id in subgraph_node_ids:
            node = task_graph.nodes.get(node_id)
            if node is None:
                continue
            if hasattr(node, 'url') and node.url:
                subgraph_urls.add(node.url)
        
        # æŸ¥æ‰¾ä¸å­å›¾åœ¨åŒä¸€é¡µé¢çš„ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹
        from graph_rag.node_types import NodeType
        business_data_types = {
            NodeType.BUSINESS_DATA,
            NodeType.USER_DATA,
            NodeType.PRODUCT_DATA,
            NodeType.ORDER_DATA,
            NodeType.CONTENT_DATA,
            NodeType.FINANCIAL_DATA,
            NodeType.LOCATION_DATA,
            NodeType.TIME_DATA
        }
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºä¸šåŠ¡æ•°æ®èŠ‚ç‚¹
        business_data_candidates = []
        
        for node_id, node in task_graph.nodes.items():
            if node_id in subgraph_node_ids:
                continue
            
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿èŠ‚ç‚¹ä¸ä¸ºNone
            if node is None:
                logger.warning(f"ğŸ¯ Warning: node {node_id} is None, skipping")
                continue
                
            if node.node_type in business_data_types:
                # è®¡ç®—ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹çš„ä¼˜å…ˆçº§
                priority = self._calculate_business_data_priority(node, subgraph_urls)
                business_data_candidates.append((node_id, priority))
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œä¼˜å…ˆé€‰æ‹©é«˜ä¼˜å…ˆçº§çš„ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹
        business_data_candidates.sort(key=lambda x: x[1], reverse=True)
        
        # é€‰æ‹©å‰5ä¸ªæœ€é«˜ä¼˜å…ˆçº§çš„ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹
        related_business_data = [node_id for node_id, _ in business_data_candidates[:5]]
        
        logger.debug(f"ğŸ¯ Found {len(related_business_data)} related business data nodes")
        return related_business_data
    
    def _calculate_business_data_priority(self, node: Any, subgraph_urls: Set[str]) -> float:
        """è®¡ç®—ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹çš„ä¼˜å…ˆçº§"""
        if node is None:
            return 0.0

        priority = 0.0
        
        # 1. é¡µé¢åŒ¹é…ä¼˜å…ˆçº§ï¼ˆæœ€é«˜ï¼‰
        if hasattr(node, 'url') and node.url in subgraph_urls:
            priority += 10.0
        
        # 2. èŠ‚ç‚¹ç±»å‹ä¼˜å…ˆçº§
        node_type_priority = {
            NodeType.BUSINESS_DATA: 8.0,
            NodeType.USER_DATA: 7.0,
            NodeType.PRODUCT_DATA: 7.0,
            NodeType.ORDER_DATA: 6.0,
            NodeType.CONTENT_DATA: 5.0,
            NodeType.FINANCIAL_DATA: 6.0,
            NodeType.LOCATION_DATA: 4.0,
            NodeType.TIME_DATA: 3.0
        }
        priority += node_type_priority.get(node.node_type, 1.0)
        
        # 3. å†…å®¹ä¸°å¯Œåº¦ä¼˜å…ˆçº§
        if hasattr(node, 'content') and node.content and len(str(node.content)) > 10:
            priority += 2.0
        
        if hasattr(node, 'text') and node.text and len(str(node.text)) > 5:
            priority += 1.5
        
        # 4. å±æ€§ä¸°å¯Œåº¦ä¼˜å…ˆçº§
        if hasattr(node, 'properties') and node.properties:
            priority += len(node.properties) * 0.5
        
        return priority
    
    
    
    def _find_nodes_for_seed(self, task_graph: TaskGraph, seed: TaskSeedPattern) -> List[str]:
        """æ‰¾åˆ°æ»¡è¶³ç§å­è¦æ±‚çš„èŠ‚ç‚¹"""
        target_nodes = []
        
        logger.debug(f"ğŸ¯ Finding nodes for seed: {seed.name}")
        logger.debug(f"ğŸ¯ Core slots: {seed.core_slots}")
        logger.debug(f"ğŸ¯ Optional slots: {seed.optional_slots}")
        
        for node_id, node in task_graph.nodes.items():
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿èŠ‚ç‚¹ä¸ä¸ºNone
            if node is None:
                logger.warning(f"ğŸ¯ Warning: node {node_id} is None, skipping")
                continue
                
            # æ£€æŸ¥æ ¸å¿ƒæ§½ä½
            for slot_name, required_type in seed.core_slots.items():
                # ç¡®ä¿ç±»å‹æ¯”è¾ƒæ­£ç¡®
                if hasattr(node.node_type, 'value'):
                    node_type_value = node.node_type.value
                else:
                    node_type_value = str(node.node_type)
                
                if isinstance(required_type, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œæ£€æŸ¥æ˜¯å¦åŒ¹é…å…¶ä¸­ä»»ä½•ä¸€ä¸ª
                    for item_type in required_type:
                        if hasattr(item_type, 'value'):
                            item_type_value = item_type.value
                        else:
                            item_type_value = str(item_type)
                        
                        if node_type_value == item_type_value:
                            target_nodes.append(node_id)
                            logger.debug(f"ğŸ¯ Found matching node {node_id} for core slot {slot_name}: {item_type_value}")
                            break
                    else:
                        continue
                    break
                else:
                    # å¦‚æœæ˜¯å•ä¸ªç±»å‹
                    if hasattr(required_type, 'value'):
                        required_type_value = required_type.value
                    else:
                        required_type_value = str(required_type)
                    
                    if node_type_value == required_type_value:
                        target_nodes.append(node_id)
                        logger.debug(f"ğŸ¯ Found matching node {node_id} for core slot {slot_name}: {node_type_value}")
                        break
            
            # æ£€æŸ¥å¯é€‰æ§½ä½
            for slot_name, required_type in seed.optional_slots.items():
                # ç¡®ä¿ç±»å‹æ¯”è¾ƒæ­£ç¡®
                if hasattr(node.node_type, 'value'):
                    node_type_value = node.node_type.value
                else:
                    node_type_value = str(node.node_type)
                
                if isinstance(required_type, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œæ£€æŸ¥æ˜¯å¦åŒ¹é…å…¶ä¸­ä»»ä½•ä¸€ä¸ª
                    for item_type in required_type:
                        if hasattr(item_type, 'value'):
                            item_type_value = item_type.value
                        else:
                            item_type_value = str(item_type)
                        
                        if node_type_value == item_type_value:
                            target_nodes.append(node_id)
                            logger.debug(f"ğŸ¯ Found matching node {node_id} for optional slot {slot_name}: {item_type_value}")
                            break
                    else:
                        continue
                    break
                else:
                    # å¦‚æœæ˜¯å•ä¸ªç±»å‹
                    if hasattr(required_type, 'value'):
                        required_type_value = required_type.value
                    else:
                        required_type_value = str(required_type)
                    
                    if node_type_value == required_type_value:
                        target_nodes.append(node_id)
                        logger.debug(f"ğŸ¯ Found matching node {node_id} for optional slot {slot_name}: {node_type_value}")
                        break
        
        logger.debug(f"ğŸ¯ Found {len(target_nodes)} target nodes for seed {seed.name}")
        return target_nodes
    
    def _bfs_sampling(self, task_graph: TaskGraph, center_node_id: str, seed: TaskSeedPattern) -> Optional[SubgraphSample]:
        """BFSé‡‡æ ·"""
        visited = set()
        queue = deque([(center_node_id, 0)])  # (node_id, distance)
        sampled_nodes = {}
        sampled_edges = {}
        business_data_nodes = []
        
        # è°ƒè¯•ï¼šæ£€æŸ¥å›¾ä¸­çš„è¾¹ç±»å‹
        edge_types_in_graph = {edge.edge_type for edge in task_graph.edges.values()}
        logger.debug(f"ğŸ¯ BFS sampling for seed {seed.name}")
        logger.debug(f"ğŸ¯ Edge types in graph: {edge_types_in_graph}")
        logger.debug(f"ğŸ¯ Seed required edge types: {seed.required_edge_types}")
        logger.debug(f"ğŸ¯ Starting from center node: {center_node_id}")
        
        while queue and len(sampled_nodes) < self.config.max_nodes:
            current_node_id, distance = queue.popleft()
            
            if current_node_id in visited or distance > self.config.max_radius:
                continue
            
            visited.add(current_node_id)
            current_node = task_graph.nodes.get(current_node_id)
            if current_node is None:
                logger.warning(f"ğŸ¯ Current node {current_node_id} is None, skipping")
                continue
            sampled_nodes[current_node_id] = current_node
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºä¸šåŠ¡æ•°æ®èŠ‚ç‚¹ï¼ˆä½¿ç”¨NodeTypeæšä¸¾ï¼‰
            from graph_rag.node_types import NodeType
            business_data_types = {
                NodeType.BUSINESS_DATA,
                NodeType.USER_DATA,
                NodeType.PRODUCT_DATA,
                NodeType.ORDER_DATA,
                NodeType.CONTENT_DATA,
                NodeType.FINANCIAL_DATA,
                NodeType.LOCATION_DATA,
                NodeType.TIME_DATA
            }
            
            if current_node.node_type in business_data_types:
                business_data_nodes.append(current_node_id)
            
                # æ·»åŠ ç›¸å…³çš„è¾¹
            edges_added = 0
            for edge in task_graph.edges.values():
                if edge.source_node_id == current_node_id and edge.target_node_id in task_graph.nodes:
                    # ç²¾å‡†æ£€æŸ¥è¾¹ç±»å‹åŒ¹é…
                    edge_matches_requirement = False
                    
                    # 1. ä¼˜å…ˆæ·»åŠ å¯¼èˆªè¾¹ï¼ˆå¦‚æœç§å­éœ€è¦å¯¼èˆªï¼‰
                    if edge.edge_type == EdgeType.NAV_TO:
                        needs_nav = self._does_seed_need_navigation(seed)
                        if needs_nav:
                            edge_matches_requirement = True
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: NAV_TO edge for navigation-requiring seed")
                        else:
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: NAV_TO edge but seed doesn't need navigation")
                    
                    # 2. æ£€æŸ¥æ˜¯å¦åŒ¹é…ç§å­è¦æ±‚çš„è¾¹ç±»å‹
                    elif seed.required_edge_types and edge.edge_type in seed.required_edge_types:
                        edge_matches_requirement = True
                        logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: matches required edge type {edge.edge_type}")
                    
                    # 3. æ£€æŸ¥æ˜¯å¦æ˜¯å†…å®¹åŒ…å«å…³ç³»ï¼ˆCONTAINSè¾¹ï¼‰
                    elif edge.edge_type == EdgeType.CONTAINS:
                        # å…è®¸é€šè¿‡CONTAINSè¾¹æ‰©å±•å­å›¾
                        if edge.source_node_id in sampled_nodes:
                            # å¦‚æœæºèŠ‚ç‚¹å·²é‡‡æ ·ï¼Œæ·»åŠ ç›®æ ‡èŠ‚ç‚¹
                            edge_matches_requirement = True
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: CONTAINS edge from sampled node to {edge.target_node_id}")
                        elif edge.target_node_id in sampled_nodes:
                            # å¦‚æœç›®æ ‡èŠ‚ç‚¹å·²é‡‡æ ·ï¼Œæ·»åŠ æºèŠ‚ç‚¹
                            edge_matches_requirement = True
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: CONTAINS edge from {edge.source_node_id} to sampled node")
                        else:
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: CONTAINS edge not connected to sampled nodes")
                    
                    # 4. æ£€æŸ¥æ˜¯å¦æ˜¯åŠŸèƒ½æ€§è¾¹ä¸”ä¸ç§å­ç›¸å…³
                    elif edge.edge_type in {EdgeType.CONTROLS, EdgeType.FILLS, EdgeType.FILTERS, EdgeType.OPENS}:
                        if self._is_functional_edge_relevant(edge, seed, sampled_nodes):
                            edge_matches_requirement = True
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: functional edge {edge.edge_type} is relevant")
                        else:
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: functional edge {edge.edge_type} not relevant")
                    
                    # 5. å¦‚æœæ²¡æœ‰æ˜ç¡®ç†ç”±ï¼Œä¸åŒ…å«è¯¥è¾¹
                    else:
                        logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: no clear reason to include {edge.edge_type}")
                    
                    if edge_matches_requirement:
                        sampled_edges[edge.edge_id] = edge
                        queue.append((edge.target_node_id, distance + 1))
                        edges_added += 1
                        logger.debug(f"ğŸ¯ Added edge {edge.edge_id} ({edge.edge_type}) to target {edge.target_node_id}")
                
                # åå‘è¾¹æ£€æŸ¥ï¼ˆç›®æ ‡èŠ‚ç‚¹æ˜¯å½“å‰èŠ‚ç‚¹ï¼‰
                if edge.target_node_id == current_node_id and edge.source_node_id in task_graph.nodes:
                    # ç²¾å‡†æ£€æŸ¥è¾¹ç±»å‹åŒ¹é…
                    edge_matches_requirement = False

                    # 1. ä¼˜å…ˆæ·»åŠ å¯¼èˆªè¾¹ï¼ˆå¦‚æœç§å­éœ€è¦å¯¼èˆªï¼‰
                    if edge.edge_type == EdgeType.NAV_TO:
                        needs_nav = self._does_seed_need_navigation(seed)
                        if needs_nav:
                            edge_matches_requirement = True
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: NAV_TO edge for navigation-requiring seed")
                        else:
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: NAV_TO edge but seed doesn't need navigation")

                    # 2. æ£€æŸ¥æ˜¯å¦åŒ¹é…ç§å­è¦æ±‚çš„è¾¹ç±»å‹
                    elif seed.required_edge_types and edge.edge_type in seed.required_edge_types:
                        edge_matches_requirement = True
                        logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: matches required edge type {edge.edge_type}")

                    # 3. æ£€æŸ¥æ˜¯å¦æ˜¯å†…å®¹åŒ…å«å…³ç³»ï¼ˆCONTAINSè¾¹ï¼‰
                    elif edge.edge_type == EdgeType.CONTAINS:
                        # å…è®¸é€šè¿‡CONTAINSè¾¹æ‰©å±•å­å›¾
                        if edge.source_node_id in sampled_nodes:
                            # å¦‚æœæºèŠ‚ç‚¹å·²é‡‡æ ·ï¼Œæ·»åŠ ç›®æ ‡èŠ‚ç‚¹
                            edge_matches_requirement = True
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: CONTAINS edge from sampled node to {edge.source_node_id}")
                        elif edge.target_node_id in sampled_nodes:
                            # å¦‚æœç›®æ ‡èŠ‚ç‚¹å·²é‡‡æ ·ï¼Œæ·»åŠ æºèŠ‚ç‚¹
                            edge_matches_requirement = True
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: CONTAINS edge from {edge.target_node_id} to sampled node")
                        else:
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: CONTAINS edge not connected to sampled nodes")

                    # 4. æ£€æŸ¥æ˜¯å¦æ˜¯åŠŸèƒ½æ€§è¾¹ä¸”ä¸ç§å­ç›¸å…³
                    elif edge.edge_type in {EdgeType.CONTROLS, EdgeType.FILLS, EdgeType.FILTERS, EdgeType.OPENS}:
                        if self._is_functional_edge_relevant(edge, seed, sampled_nodes):
                            edge_matches_requirement = True
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: functional edge {edge.edge_type} is relevant")
                        else:
                            logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: functional edge {edge.edge_type} not relevant")

                    # 5. å¦‚æœæ²¡æœ‰æ˜ç¡®ç†ç”±ï¼Œä¸åŒ…å«è¯¥è¾¹
                    else:
                        logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: no clear reason to include {edge.edge_type}")

                    if edge_matches_requirement:
                        sampled_edges[edge.edge_id] = edge
                        queue.append((edge.source_node_id, distance + 1))
                        edges_added += 1
                        logger.debug(f"ğŸ¯ Added edge {edge.edge_id} ({edge.edge_type}) to target {edge.source_node_id}")
            
            logger.debug(f"ğŸ¯ Added {edges_added} edges from node {current_node_id}")
        
        # å¦‚æœå­å›¾ä¸­æ²¡æœ‰ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹ï¼Œå°è¯•æ·»åŠ ä¸€äº›
        if not business_data_nodes and len(sampled_nodes) < self.config.max_nodes:
            # æŸ¥æ‰¾ä¸å½“å‰å­å›¾ç›¸å…³çš„ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹
            related_business_data = self._find_related_business_data(task_graph, list(sampled_nodes.keys()))
            for node_id in related_business_data:
                if len(sampled_nodes) < self.config.max_nodes:
                    node = task_graph.nodes.get(node_id)
                    if node is not None:
                        sampled_nodes[node_id] = node
                    logger.debug(f"ğŸ¯ Added business data node {node_id} to subgraph")
        
        if len(sampled_nodes) >= self.config.min_nodes:
            return SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=center_node_id,
                radius=self.config.max_radius,
                strategy=self.config.strategy,
                task_seed=seed
            )
        
        return None
    
    
    
    def _radius_based_sampling(self, task_graph: TaskGraph, seed: TaskSeedPattern, radius: int) -> Optional[SubgraphSample]:
        """åŸºäºåŠå¾„çš„é‡‡æ ·"""
        # æ‰¾åˆ°ç§å­è¦æ±‚çš„èŠ‚ç‚¹ç±»å‹
        target_nodes = self._find_nodes_for_seed(task_graph, seed)
        
        if not target_nodes:
            return None
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªç›®æ ‡èŠ‚ç‚¹ä½œä¸ºä¸­å¿ƒ
        center_node_id = random.choice(target_nodes)
        
        # ä½¿ç”¨BFSé‡‡æ ·ï¼Œä½†é™åˆ¶åŠå¾„
        return self._bfs_sampling_with_radius(task_graph, center_node_id, seed, radius)
    
    def _bfs_sampling_with_radius(self, task_graph: TaskGraph, center_node_id: str, seed: TaskSeedPattern, radius: int) -> Optional[SubgraphSample]:
        """å¸¦åŠå¾„é™åˆ¶çš„BFSé‡‡æ ·"""
        visited = set()
        queue = deque([(center_node_id, 0)])
        sampled_nodes = {}
        sampled_edges = {}
        
        while queue and len(sampled_nodes) < self.config.max_nodes:
            current_node_id, distance = queue.popleft()
            
            if current_node_id in visited or distance > radius:
                continue
            
            visited.add(current_node_id)
            current_node = task_graph.nodes.get(current_node_id)
            if current_node is None:
                logger.warning(f"ğŸ¯ Current node {current_node_id} is None, skipping")
                continue
            sampled_nodes[current_node_id] = current_node
            
            # æ·»åŠ ç›¸å…³çš„è¾¹
            for edge in task_graph.edges.values():
                if edge.source_node_id == current_node_id and edge.target_node_id in task_graph.nodes:
                    # æ£€æŸ¥è¾¹ç±»å‹åŒ¹é…
                    edge_matches_requirement = False
                    
                    # ä¼˜å…ˆæ·»åŠ å¯¼èˆªè¾¹
                    if edge.edge_type == EdgeType.NAV_TO:
                        edge_matches_requirement = True
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç§å­è¦æ±‚çš„è¾¹ç±»å‹
                    elif seed.required_edge_types and edge.edge_type in seed.required_edge_types:
                        edge_matches_requirement = True
                    # å¦‚æœæ²¡æœ‰ç‰¹å®šè¦æ±‚ï¼Œæ·»åŠ æ‰€æœ‰è¾¹
                    elif not seed.required_edge_types:
                        edge_matches_requirement = True
                    
                    if edge_matches_requirement:
                        sampled_edges[edge.edge_id] = edge
                        queue.append((edge.target_node_id, distance + 1))
                        logger.debug(f"ğŸ¯ BFS with radius: added edge {edge.edge_id} ({edge.edge_type}) to target {edge.target_node_id}")
        
        if len(sampled_nodes) >= self.config.min_nodes:
            return SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=center_node_id,
                radius=radius,
                strategy=self.config.strategy,
                task_seed=seed
            )
        
        return None
    
    def _validate_subgraph(self, subgraph: SubgraphSample, seed: TaskSeedPattern) -> bool:
        """éªŒè¯å­å›¾æ˜¯å¦æ»¡è¶³ç§å­è¦æ±‚ - å¢å¼ºè´¨é‡æ§åˆ¶"""
        logger.debug(f"ğŸ¯ Validating subgraph for seed {seed.name} with {len(subgraph.nodes)} nodes and {len(subgraph.edges)} edges")

        # æ£€æŸ¥èŠ‚ç‚¹æ•°é‡ - ä¸¥æ ¼æ§åˆ¶è´¨é‡
        if len(subgraph.nodes) < self.config.min_nodes:  # ä½¿ç”¨é…ç½®çš„æœ€å°èŠ‚ç‚¹æ•°
            logger.debug(f"ğŸ¯ Subgraph validation failed: too few nodes ({len(subgraph.nodes)} < {self.config.min_nodes})")
            return False

        if len(subgraph.nodes) > self.config.max_nodes:
            logger.debug(f"ğŸ¯ Subgraph validation failed: too many nodes ({len(subgraph.nodes)} > {self.config.max_nodes})")
            return False

        # æ£€æŸ¥å­å›¾è¿é€šæ€§ - æ–°å¢è´¨é‡æ£€æŸ¥
        if not self._validate_subgraph_connectivity(subgraph.nodes, subgraph.edges):
            logger.debug(f"ğŸ¯ Subgraph validation failed: disconnected components")
            return False

        # æ£€æŸ¥å¯æ‰§è¡Œæ€§åˆ†æ•° - ç¡®ä¿è´¨é‡é˜ˆå€¼
        executability_score = self._calculate_executability_score(subgraph)
        min_quality_score = 5.0  # è®¾ç½®æœ€å°è´¨é‡åˆ†æ•°
        if executability_score < min_quality_score:
            logger.debug(f"ğŸ¯ Subgraph validation failed: low executability score ({executability_score} < {min_quality_score})")
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…éœ€çš„èŠ‚ç‚¹ç±»å‹ - æ”¾å®½æ£€æŸ¥
        subgraph_node_types = {node.node_type for node in subgraph.nodes.values() if node is not None}
        logger.debug(f"ğŸ¯ Subgraph node types: {subgraph_node_types}")
        
        # æ£€æŸ¥æ ¸å¿ƒæ§½ä½ - æ”¾å®½æ£€æŸ¥ï¼Œåªè¦æœ‰ä»»ä½•åŒ¹é…å³å¯
        core_slot_types = set()
        for slot_value in seed.core_slots.values():
            if isinstance(slot_value, list):
                core_slot_types.update(slot_value)
            else:
                core_slot_types.add(slot_value)
        
        if core_slot_types:
            intersection = subgraph_node_types.intersection(core_slot_types)
            if not intersection:
                logger.debug(f"ğŸ¯ Subgraph validation failed: no core slot types found. Required: {core_slot_types}, Available: {subgraph_node_types}")
                return False
            else:
                logger.debug(f"ğŸ¯ Found matching core slot types: {intersection}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…éœ€çš„è¾¹ç±»å‹ - æ”¾å®½æ£€æŸ¥ï¼Œè¾¹ç±»å‹ä¸æ˜¯å¿…éœ€çš„
        subgraph_edge_types = {edge.edge_type for edge in subgraph.edges.values()}
        logger.debug(f"ğŸ¯ Subgraph edge types: {subgraph_edge_types}")
        
        if seed.required_edge_types:
            intersection = subgraph_edge_types.intersection(seed.required_edge_types)
            if not intersection:
                logger.debug(f"ğŸ¯ Warning: no required edge types found, but continuing. Required: {seed.required_edge_types}, Available: {subgraph_edge_types}")
            else:
                logger.debug(f"ğŸ¯ Found matching edge types: {intersection}")
        
        # ç‰¹åˆ«æ£€æŸ¥å¯¼èˆªç›¸å…³çš„ç§å­ - æ”¾å®½æ£€æŸ¥
        if seed.seed_type in [TaskSeedType.MULTI_HOP_NAVIGATION, TaskSeedType.BASIC_NAVIGATION, TaskSeedType.BREADCRUMB_NAVIGATION]:
            # ç¡®ä¿æœ‰å¯¼èˆªèŠ‚ç‚¹
            navigation_types = {NodeType.NAVIGATION, NodeType.LINK, NodeType.BREADCRUMB, NodeType.BUTTON}
            if not subgraph_node_types.intersection(navigation_types):
                logger.debug(f"ğŸ¯ Navigation subgraph validation failed: no navigation nodes found")
                return False
            
            # å¦‚æœæœ‰å¯¼èˆªè¾¹æ›´å¥½ï¼Œä½†ä¸æ˜¯å¿…éœ€çš„
            if EdgeType.NAV_TO not in subgraph_edge_types:
                logger.debug(f"ğŸ¯ Navigation subgraph has no NAV_TO edges, but continuing with navigation nodes")
        
        logger.debug(f"ğŸ¯ Subgraph validation passed for seed {seed.name}")
        return True
    
    
    
    def _should_include_edge_for_seed(self, edge: Any, seed: TaskSeedPattern, sampled_nodes: Dict[str, Any]) -> bool:
        """ç²¾å‡†åˆ¤æ–­è¾¹æ˜¯å¦åº”è¯¥è¢«åŒ…å«åœ¨å­å›¾ä¸­"""
        # 1. æ£€æŸ¥è¾¹ç±»å‹æ˜¯å¦åŒ¹é…ç§å­è¦æ±‚
        if seed.required_edge_types and edge.edge_type in seed.required_edge_types:
            # å¦‚æœæºèŠ‚ç‚¹æˆ–ç›®æ ‡èŠ‚ç‚¹åœ¨å·²é‡‡æ ·èŠ‚ç‚¹ä¸­ï¼Œå°±åŒ…å«è¿™æ¡è¾¹ï¼ˆç”¨äºæ‰©å±•å­å›¾ï¼‰
            if edge.source_node_id in sampled_nodes or edge.target_node_id in sampled_nodes:
                logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: matches required edge type {edge.edge_type} and connected to sampled nodes")
                return True
            else:
                logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: matches required edge type {edge.edge_type} but not connected to sampled nodes")
                return False
        
        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯å¯¼èˆªè¾¹ä¸”ç§å­éœ€è¦å¯¼èˆª
        if edge.edge_type == EdgeType.NAV_TO:
            needs_nav = self._does_seed_need_navigation(seed)
            if needs_nav:
                # å¦‚æœæºèŠ‚ç‚¹æˆ–ç›®æ ‡èŠ‚ç‚¹åœ¨å·²é‡‡æ ·èŠ‚ç‚¹ä¸­ï¼Œå°±åŒ…å«è¿™æ¡è¾¹ï¼ˆç”¨äºæ‰©å±•å­å›¾ï¼‰
                if edge.source_node_id in sampled_nodes or edge.target_node_id in sampled_nodes:
                    logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: NAV_TO edge connected to sampled nodes")
                    return True
                else:
                    logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: NAV_TO edge not connected to sampled nodes")
                    return False
            else:
                logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: NAV_TO edge but seed doesn't need navigation")
                return False
        
        # 3. æ£€æŸ¥æ˜¯å¦æ˜¯å†…å®¹åŒ…å«å…³ç³»
        if edge.edge_type == EdgeType.CONTAINS:
            # å¦‚æœæºèŠ‚ç‚¹æˆ–ç›®æ ‡èŠ‚ç‚¹åœ¨å·²é‡‡æ ·èŠ‚ç‚¹ä¸­ï¼Œå°±åŒ…å«è¿™æ¡è¾¹ï¼ˆç”¨äºæ‰©å±•å­å›¾ï¼‰
            if edge.source_node_id in sampled_nodes or edge.target_node_id in sampled_nodes:
                logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: CONTAINS edge connected to sampled nodes")
                return True
            else:
                logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: CONTAINS edge not connected to sampled nodes")
                return False
        
        # 4. æ£€æŸ¥æ˜¯å¦æ˜¯åŠŸèƒ½æ€§è¾¹ï¼ˆå¦‚æ§åˆ¶ã€å¡«å……ç­‰ï¼‰
        functional_edge_types = {EdgeType.CONTROLS, EdgeType.FILLS, EdgeType.FILTERS, EdgeType.OPENS}
        if edge.edge_type in functional_edge_types:
            # æ£€æŸ¥æ˜¯å¦ä¸å·²é‡‡æ ·çš„èŠ‚ç‚¹å½¢æˆæœ‰æ„ä¹‰çš„è¿æ¥
            if self._is_functional_edge_relevant(edge, seed, sampled_nodes):
                logger.debug(f"ğŸ¯ Edge {edge.edge_id} included: functional edge {edge.edge_type} is relevant")
                return True
            else:
                logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: functional edge {edge.edge_type} not relevant")
                return False
        
        # 5. é»˜è®¤ä¸åŒ…å«ï¼Œé™¤éæœ‰æ˜ç¡®ç†ç”±
        logger.debug(f"ğŸ¯ Edge {edge.edge_id} excluded: no clear reason to include {edge.edge_type}")
        return False
    
    def _is_functional_edge_relevant(self, edge: Any, seed: TaskSeedPattern, sampled_nodes: Dict[str, Any]) -> bool:
        """åˆ¤æ–­åŠŸèƒ½æ€§è¾¹æ˜¯å¦ä¸ç§å­ç›¸å…³"""
        # å¦‚æœæºèŠ‚ç‚¹æˆ–ç›®æ ‡èŠ‚ç‚¹åœ¨å·²é‡‡æ ·èŠ‚ç‚¹ä¸­ï¼Œå°±åŒ…å«è¿™æ¡è¾¹ï¼ˆç”¨äºæ‰©å±•å­å›¾ï¼‰
        if edge.source_node_id not in sampled_nodes and edge.target_node_id not in sampled_nodes:
            return False
        
        # æ£€æŸ¥è¾¹çš„ç«¯ç‚¹æ˜¯å¦ä¸ç§å­è¦æ±‚çš„èŠ‚ç‚¹ç±»å‹åŒ¹é…
        source_node = sampled_nodes.get(edge.source_node_id)
        target_node = sampled_nodes.get(edge.target_node_id)

        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
        if source_node is None or target_node is None:
            return False

        # æ£€æŸ¥æ˜¯å¦å½¢æˆç§å­è¦æ±‚çš„æ¨¡å¼
        if seed.core_slots:
            source_type = source_node.node_type
            target_type = target_node.node_type
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…æ ¸å¿ƒæ§½ä½è¦æ±‚
            for slot_name, required_type in seed.core_slots.items():
                if isinstance(required_type, list):
                    for item_type in required_type:
                        if source_type == item_type or target_type == item_type:
                            logger.debug(f"ğŸ¯ Functional edge relevant: matches core slot {slot_name} ({item_type})")
                            return True
                elif source_type == required_type or target_type == required_type:
                    logger.debug(f"ğŸ¯ Functional edge relevant: matches core slot {slot_name} ({required_type})")
                    return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ç§å­åç§°æè¿°çš„åŠŸèƒ½åŒ¹é…
        seed_name_lower = seed.name.lower()
        if edge.edge_type == EdgeType.CONTROLS and 'control' in seed_name_lower:
            return True
        if edge.edge_type == EdgeType.FILLS and 'fill' in seed_name_lower:
            return True
        if edge.edge_type == EdgeType.FILTERS and 'filter' in seed_name_lower:
            return True
        
        return False
    
    
    def _calculate_node_distance(self, task_graph: TaskGraph, node_a: str, node_b: str) -> int:
        """è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„è·ç¦»ï¼ˆBFSï¼‰"""
        if node_a == node_b:
            return 0
        
        queue = deque([(node_a, 0)])
        visited = {node_a}
        
        while queue:
            current_node, distance = queue.popleft()
            
            for edge in task_graph.edges.values():
                if edge.source_node_id == current_node and edge.target_node_id not in visited:
                    if edge.target_node_id == node_b:
                        return distance + 1
                    visited.add(edge.target_node_id)
                    queue.append((edge.target_node_id, distance + 1))
                
                if edge.target_node_id == current_node and edge.source_node_id not in visited:
                    if edge.source_node_id == node_b:
                        return distance + 1
                    visited.add(edge.source_node_id)
                    queue.append((edge.source_node_id, distance + 1))
        
        return float('inf')  # ä¸å¯è¾¾
    
    
    # ==================== é‡æ„åçš„å¼ºç»‘å®šé‡‡æ ·æ–¹æ³• ====================
    
    def _analyze_graph_structure(self, task_graph: TaskGraph) -> None:
        """åˆ†æå›¾ç»“æ„ï¼Œè®°å½•èŠ‚ç‚¹å’Œè¾¹ç±»å‹åˆ†å¸ƒ"""
        # èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ
        node_type_counts = {}
        for node in task_graph.nodes.values():
            if node is None:
                continue
            node_type = node.node_type.value
            node_type_counts[node_type] = node_type_counts.get(node_type, 0) + 1
        
        logger.info(f"ğŸ¯ Node type distribution: {node_type_counts}")
        
        # è¾¹ç±»å‹åˆ†å¸ƒ
        edge_type_counts = {}
        for edge in task_graph.edges.values():
            edge_type = edge.edge_type.value
            edge_type_counts[edge_type] = edge_type_counts.get(edge_type, 0) + 1
        
        logger.info(f"ğŸ¯ Edge type distribution: {edge_type_counts}")
    
    def _get_seed_anchor_nodes(self, seed: TaskSeedPattern) -> Set[Union[NodeType, List[NodeType]]]:
        """è·å–ç§å­å¿…éœ€çš„èŠ‚ç‚¹ç±»å‹ï¼ˆé”šç‚¹ï¼‰"""
        anchor_nodes = set()
        
        # 1. æ ¸å¿ƒæ§½ä½èŠ‚ç‚¹ç±»å‹
        if seed.core_slots:
            for slot_name, slot_value in seed.core_slots.items():
                if isinstance(slot_value, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°†æ•´ä¸ªåˆ—è¡¨ä½œä¸ºä¸€ä¸ªè¦æ±‚
                    anchor_nodes.add(tuple(slot_value))
                else:
                    # å¦‚æœæ˜¯å•ä¸ªç±»å‹ï¼Œç›´æ¥æ·»åŠ 
                    anchor_nodes.add(slot_value)
        
        # 2. æ ¹æ®ç§å­ç±»å‹æ·»åŠ ç‰¹å®šé”šç‚¹
        if seed.seed_type == TaskSeedType.BUSINESS_SEARCH_FILTER:
            anchor_nodes.update([NodeType.SEARCH_BOX, NodeType.BUTTON, NodeType.RESULT_ITEM])
        elif seed.seed_type == TaskSeedType.MULTI_HOP_NAVIGATION:
            anchor_nodes.update([NodeType.NAVIGATION, NodeType.LINK, NodeType.BUTTON])
        elif seed.seed_type == TaskSeedType.USER_NAVIGATION:
            anchor_nodes.update([NodeType.USER_DATA, NodeType.NAVIGATION, NodeType.PAGE])
        elif seed.seed_type == TaskSeedType.PRODUCT_NAVIGATION:
            anchor_nodes.update([NodeType.PRODUCT_DATA, NodeType.NAVIGATION, NodeType.PAGE])
        elif seed.seed_type == TaskSeedType.ORDER_NAVIGATION:
            anchor_nodes.update([NodeType.ORDER_DATA, NodeType.NAVIGATION, NodeType.PAGE])
        elif seed.seed_type == TaskSeedType.MIXED_DATA_NAVIGATION:
            anchor_nodes.update([NodeType.NAVIGATION, NodeType.PAGE])
            # æ··åˆæ•°æ®ç±»å‹éœ€è¦è‡³å°‘ä¸¤ç§ä¸åŒçš„æ•°æ®ç±»å‹
            anchor_nodes.update([NodeType.BUSINESS_DATA, NodeType.USER_DATA, NodeType.PRODUCT_DATA, NodeType.ORDER_DATA])
        
        # 3. æ ¹æ®ç§å­åç§°æ¨æ–­é”šç‚¹
        seed_name_lower = seed.name.lower()
        if 'form' in seed_name_lower:
            anchor_nodes.add(NodeType.FORM)
        if 'search' in seed_name_lower:
            anchor_nodes.add(NodeType.SEARCH_BOX)
        if 'navigation' in seed_name_lower:
            anchor_nodes.add(NodeType.NAVIGATION)
        if 'table' in seed_name_lower:
            anchor_nodes.add(NodeType.TABLE)
        # æ–°å¢ï¼šæ ¹æ®æ•°æ®ç±»å‹æ¨æ–­é”šç‚¹
        if 'user' in seed_name_lower:
            anchor_nodes.add(NodeType.USER_DATA)
        if 'product' in seed_name_lower:
            anchor_nodes.add(NodeType.PRODUCT_DATA)
        if 'order' in seed_name_lower:
            anchor_nodes.add(NodeType.ORDER_DATA)
        if 'business' in seed_name_lower:
            anchor_nodes.add(NodeType.BUSINESS_DATA)
        if 'mixed' in seed_name_lower:
            # æ··åˆæ•°æ®ç±»å‹éœ€è¦å¤šç§æ•°æ®ç±»å‹æ”¯æŒ
            anchor_nodes.update([NodeType.BUSINESS_DATA, NodeType.USER_DATA, NodeType.PRODUCT_DATA, NodeType.ORDER_DATA])
        
        logger.debug(f"ğŸ¯ Anchor nodes for {seed.name}: {anchor_nodes}")
        return anchor_nodes
    
    def _get_recommended_strategies_for_seed(self, seed: TaskSeedPattern) -> List[SamplingStrategy]:
        """æ™ºèƒ½ç­–ç•¥é€‰æ‹© - æ ¹æ®ç§å­ç±»å‹å’Œç‰¹å¾æ¨èæœ€é€‚åˆçš„é‡‡æ ·ç­–ç•¥ - ä¿®å¤ç‰ˆæœ¬"""
        recommended_strategies = []
        
        # è·å–ç§å­åˆ†ç±»
        seed_category = getattr(seed, 'seed_category', 'interaction')
        
        # 1. åŸºäºç§å­åˆ†ç±»çš„ç­–ç•¥é€‰æ‹©
        if seed_category == "business":
            # ä¸šåŠ¡ç§å­ä¼˜å…ˆä½¿ç”¨ç›®æ ‡å¯¼å‘å’Œå…³ç³»ä¸­å¿ƒç­–ç•¥
            recommended_strategies.extend([
                SamplingStrategy.GOAL_CONDITIONED,  # ä¸šåŠ¡ä»»åŠ¡é€šå¸¸æ˜¯ç›®æ ‡å¯¼å‘çš„
                SamplingStrategy.RELATION_CENTRIC,  # ä¸šåŠ¡æ•°æ®é—´çš„å…³ç³»å¾ˆé‡è¦
                SamplingStrategy.ELEMENT_CENTRIC,   # ä¸šåŠ¡å…ƒç´ æ˜¯æ ¸å¿ƒ
            ])
        else:
            # äº¤äº’ç§å­ä½¿ç”¨å…ƒç´ ä¸­å¿ƒå’ŒåŠŸèƒ½æ¨¡å—ç­–ç•¥
            recommended_strategies.extend([
                SamplingStrategy.ELEMENT_CENTRIC,   # äº¤äº’å…ƒç´ æ˜¯æ ¸å¿ƒ
                SamplingStrategy.FUNCTIONAL_MODULE, # åŠŸèƒ½æ¨¡å—å¯¼å‘
                SamplingStrategy.GOAL_CONDITIONED,  # ç›®æ ‡å¯¼å‘ä½œä¸ºå¤‡é€‰
            ])
        
        # 2. åŸºäºç§å­åç§°çš„æ™ºèƒ½åŒ¹é…
        seed_name_lower = seed.name.lower()
        
        if 'search' in seed_name_lower or 'filter' in seed_name_lower:
            recommended_strategies.extend([
                SamplingStrategy.ELEMENT_CENTRIC,  # æœç´¢æ¡†å’Œè¿‡æ»¤å™¨é€šå¸¸æ˜¯å…³é”®å…ƒç´ 
                SamplingStrategy.GOAL_CONDITIONED,  # ç›®æ ‡å¯¼å‘çš„æœç´¢ä»»åŠ¡
            ])
        
        elif 'form' in seed_name_lower or 'filling' in seed_name_lower:
            recommended_strategies.extend([
                SamplingStrategy.ELEMENT_CENTRIC,  # è¡¨å•å…ƒç´ æ˜¯æ ¸å¿ƒ
                SamplingStrategy.RELATION_CENTRIC,  # è¡¨å•å­—æ®µé—´çš„å…³ç³»å¾ˆé‡è¦
            ])
        
        elif 'navigation' in seed_name_lower or 'nav' in seed_name_lower:
            recommended_strategies.extend([
                SamplingStrategy.RELATION_CENTRIC,  # å¯¼èˆªå…³ç³»æ˜¯æ ¸å¿ƒ
                SamplingStrategy.GOAL_CONDITIONED,  # ç›®æ ‡å¯¼å‘çš„å¯¼èˆª
            ])
        
        elif 'data' in seed_name_lower or 'extraction' in seed_name_lower:
            recommended_strategies.extend([
                SamplingStrategy.RELATION_CENTRIC,  # æ•°æ®å…³ç³»å¾ˆé‡è¦
                SamplingStrategy.ELEMENT_CENTRIC,  # æ•°æ®å…ƒç´ æ˜¯æ ¸å¿ƒ
            ])
        
        elif 'comparison' in seed_name_lower or 'compare' in seed_name_lower:
            recommended_strategies.extend([
                SamplingStrategy.RELATION_CENTRIC,  # æ¯”è¾ƒå…³ç³»æ˜¯æ ¸å¿ƒ
                SamplingStrategy.GOAL_CONDITIONED,  # ç›®æ ‡å¯¼å‘çš„æ¯”è¾ƒ
            ])
        
        # æ–°å¢ï¼šé€šç”¨äº¤äº’å…ƒç´ çš„ç­–ç•¥åŒ¹é…
        elif any(keyword in seed_name_lower for keyword in ['button', 'menu', 'tab', 'modal', 'toast', 'breadcrumb', 'pagination', 'expand', 'scroll']):
            recommended_strategies.extend([
                SamplingStrategy.ELEMENT_CENTRIC,  # äº¤äº’å…ƒç´ æ˜¯æ ¸å¿ƒ
                SamplingStrategy.FUNCTIONAL_MODULE,  # åŠŸèƒ½æ¨¡å—å¯¼å‘
                SamplingStrategy.RELATION_CENTRIC,  # äº¤äº’å…³ç³»ä¹Ÿå¾ˆé‡è¦
            ])
        
        # 3. åŸºäºç§å­ç±»å‹çš„ç²¾ç¡®åŒ¹é…
        if seed.seed_type in [TaskSeedType.MULTI_HOP_NAVIGATION, TaskSeedType.BASIC_NAVIGATION]:
            recommended_strategies.extend([
                SamplingStrategy.RELATION_CENTRIC,
                SamplingStrategy.GOAL_CONDITIONED,
            ])

        elif seed.seed_type in [TaskSeedType.BUSINESS_SEARCH_FILTER]:
            recommended_strategies.extend([
                SamplingStrategy.ELEMENT_CENTRIC,
                SamplingStrategy.RELATION_CENTRIC,
            ])

        # 4. åŸºäºç§å­å¤æ‚åº¦çš„ç­–ç•¥è°ƒæ•´
        complexity = self._assess_seed_complexity(seed)
        if complexity == "high":
            # å¤æ‚ç§å­ä¼˜å…ˆä½¿ç”¨é«˜æ•ˆç­–ç•¥
            recommended_strategies = [SamplingStrategy.ELEMENT_CENTRIC] + recommended_strategies
        elif complexity == "medium":
            # ä¸­ç­‰å¤æ‚åº¦ä½¿ç”¨å¹³è¡¡ç­–ç•¥
            if SamplingStrategy.ELEMENT_CENTRIC not in recommended_strategies:
                recommended_strategies.insert(0, SamplingStrategy.ELEMENT_CENTRIC)
        
        # 5. å»é‡å¹¶ä¿æŒé¡ºåº
        seen = set()
        unique_strategies = []
        for strategy in recommended_strategies:
            if strategy not in seen:
                seen.add(strategy)
                unique_strategies.append(strategy)
        
        # 6. å¦‚æœæ²¡æœ‰æ¨èç­–ç•¥ï¼Œä½¿ç”¨æ™ºèƒ½é»˜è®¤ç­–ç•¥
        if not unique_strategies:
            unique_strategies = self._get_default_strategies_for_seed(seed)
        
        # 7. é™åˆ¶ç­–ç•¥æ•°é‡ï¼Œæé«˜æ•ˆç‡
        max_strategies = 3
        if len(unique_strategies) > max_strategies:
            unique_strategies = unique_strategies[:max_strategies]
        
        logger.debug(f"ğŸ¯ Smart strategy selection for {seed.name} (category: {seed_category}): {[s.value for s in unique_strategies]} (complexity: {complexity})")
        return unique_strategies
    
    def _assess_seed_complexity(self, seed: TaskSeedPattern) -> str:
        """è¯„ä¼°ç§å­å¤æ‚åº¦"""
        complexity_score = 0
        
        # 1. åŸºäºæ ¸å¿ƒæ§½ä½æ•°é‡
        complexity_score += len(seed.core_slots) * 2
        
        # 2. åŸºäºå¯é€‰æ§½ä½æ•°é‡
        complexity_score += len(seed.optional_slots)
        
        # 3. åŸºäºå¿…éœ€è¾¹ç±»å‹æ•°é‡
        if seed.required_edge_types:
            complexity_score += len(seed.required_edge_types)
        
        # 4. åŸºäºç§å­ç±»å‹
        if seed.seed_type in [TaskSeedType.MULTI_HOP_NAVIGATION]:
            complexity_score += 3
        elif seed.seed_type in [TaskSeedType.BUSINESS_SEARCH_FILTER]:
            complexity_score += 2
        
        # 5. åŸºäºç§å­åç§°å…³é”®è¯
        seed_name_lower = seed.name.lower()
        if any(keyword in seed_name_lower for keyword in ['multi', 'complex', 'advanced']):
            complexity_score += 2
        elif any(keyword in seed_name_lower for keyword in ['simple', 'basic']):
            complexity_score -= 1
        
        # 6. åˆ†ç±»å¤æ‚åº¦
        if complexity_score >= 8:
            return "high"
        elif complexity_score >= 4:
            return "medium"
        else:
            return "low"
    
    def _get_default_strategies_for_seed(self, seed: TaskSeedPattern) -> List[SamplingStrategy]:
        """ä¸ºç§å­è·å–é»˜è®¤ç­–ç•¥"""
        # æ ¹æ®ç§å­å¤æ‚åº¦é€‰æ‹©é»˜è®¤ç­–ç•¥
        complexity = self._assess_seed_complexity(seed)
        
        if complexity == "high":
            return [SamplingStrategy.ELEMENT_CENTRIC, SamplingStrategy.RELATION_CENTRIC]
        elif complexity == "medium":
            return [SamplingStrategy.ELEMENT_CENTRIC, SamplingStrategy.GOAL_CONDITIONED]
        else:
            return [SamplingStrategy.ELEMENT_CENTRIC]
    
    def _execute_seed_bound_sampling(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                    required_node_types: Set[NodeType], 
                                    recommended_strategies: List[SamplingStrategy]) -> List[SubgraphSample]:
        """ç®€åŒ–çš„ç§å­ç»‘å®šé‡‡æ · - ç›´æ¥åŸºäºç­–ç•¥é‡‡æ ·"""
        subgraphs = []
        
        logger.info(f"ğŸ¯ Executing simple seed-bound sampling for {seed.name}")
        
        # ç›´æ¥åŸºäºæ¨èç­–ç•¥è¿›è¡Œé‡‡æ ·ï¼Œä¸è¿›è¡Œå¤æ‚çš„é”šç‚¹è¡¥å……
        for strategy in recommended_strategies:
            try:
                if strategy == SamplingStrategy.ELEMENT_CENTRIC:
                    strategy_subgraphs = self._simple_element_centric_sampling(task_graph, seed)
                elif strategy == SamplingStrategy.GOAL_CONDITIONED:
                    strategy_subgraphs = self._simple_goal_conditioned_sampling(task_graph, seed)
                elif strategy == SamplingStrategy.RELATION_CENTRIC:
                    strategy_subgraphs = self._simple_relation_centric_sampling(task_graph, seed)
                elif strategy == SamplingStrategy.CURRICULUM_RADIUS:
                    strategy_subgraphs = self._curriculum_radius_sampling(task_graph, [seed])
                elif strategy == SamplingStrategy.FUNCTIONAL_MODULE:
                    strategy_subgraphs = self._functional_module_sampling(task_graph, [seed])
                else:
                    # é»˜è®¤ä½¿ç”¨å…ƒç´ ä¸­å¿ƒé‡‡æ ·
                    strategy_subgraphs = self._simple_element_centric_sampling(task_graph, seed)
                
                subgraphs.extend(strategy_subgraphs)
                logger.info(f"ğŸ¯ Strategy {strategy.value} generated {len(strategy_subgraphs)} subgraphs")
                
                # é™åˆ¶æ¯ä¸ªç­–ç•¥ç”Ÿæˆçš„å­å›¾æ•°é‡
                if len(subgraphs) >= 10:
                    break
                    
            except Exception as e:
                logger.error(f"ğŸ¯ Strategy {strategy.value} failed: {e}")
                continue
        
        logger.info(f"ğŸ¯ Total subgraphs generated for {seed.name}: {len(subgraphs)}")
        return subgraphs
    
    def _simple_element_centric_sampling(self, task_graph: TaskGraph, seed: TaskSeedPattern) -> List[SubgraphSample]:
        """ç®€åŒ–çš„å…ƒç´ ä¸­å¿ƒé‡‡æ ·"""
        subgraphs = []
        
        # æ‰¾åˆ°æ»¡è¶³ç§å­è¦æ±‚çš„èŠ‚ç‚¹
        target_nodes = self._find_nodes_for_seed(task_graph, seed)
        logger.debug(f"ğŸ¯ Found {len(target_nodes)} target nodes for simple element-centric sampling")
        
        # é™åˆ¶å¤„ç†æ•°é‡
        max_attempts = min(len(target_nodes), 5)
        
        for i, center_node_id in enumerate(target_nodes[:max_attempts]):
            center_node = task_graph.nodes.get(center_node_id)
            if center_node is None:
                continue
            
            # ä½¿ç”¨ç®€å•çš„BFSé‡‡æ ·
            subgraph = self._bfs_sampling(task_graph, center_node_id, seed)
            
            if subgraph and self._validate_subgraph(subgraph, seed):
                subgraphs.append(subgraph)
                logger.debug(f"ğŸ¯ Added simple element-centric subgraph with {len(subgraph.nodes)} nodes")
        
        return subgraphs
    
    def _simple_goal_conditioned_sampling(self, task_graph: TaskGraph, seed: TaskSeedPattern) -> List[SubgraphSample]:
        """ç®€åŒ–çš„ç›®æ ‡æ¡ä»¶é‡‡æ ·"""
        subgraphs = []
        
        # æ‰¾åˆ°æ»¡è¶³ç§å­è¦æ±‚çš„èŠ‚ç‚¹
        target_nodes = self._find_nodes_for_seed(task_graph, seed)
        logger.debug(f"ğŸ¯ Found {len(target_nodes)} target nodes for simple goal-conditioned sampling")
        
        # é™åˆ¶å¤„ç†æ•°é‡
        max_attempts = min(len(target_nodes), 5)
        
        for i, target_node_id in enumerate(target_nodes[:max_attempts]):
            # ä½¿ç”¨ç®€å•çš„åå‘é‡‡æ ·
            subgraph = self._simple_backward_sampling(task_graph, target_node_id, seed)
            
            if subgraph and self._validate_subgraph(subgraph, seed):
                subgraphs.append(subgraph)
                logger.debug(f"ğŸ¯ Added simple goal-conditioned subgraph with {len(subgraph.nodes)} nodes")
        
        return subgraphs
    
    def _simple_relation_centric_sampling(self, task_graph: TaskGraph, seed: TaskSeedPattern) -> List[SubgraphSample]:
        """ç®€åŒ–çš„å…³ç³»ä¸­å¿ƒé‡‡æ ·"""
        subgraphs = []
        
        # æ‰¾åˆ°æ»¡è¶³ç§å­è¦æ±‚çš„èŠ‚ç‚¹
        target_nodes = self._find_nodes_for_seed(task_graph, seed)
        logger.debug(f"ğŸ¯ Found {len(target_nodes)} target nodes for simple relation-centric sampling")
        
        # é™åˆ¶å¤„ç†æ•°é‡
        max_attempts = min(len(target_nodes), 5)
        
        for i, target_node_id in enumerate(target_nodes[:max_attempts]):
            # ä½¿ç”¨ç®€å•çš„åå‘é‡‡æ ·
            subgraph = self._simple_backward_sampling(task_graph, target_node_id, seed)
            
            if subgraph and self._validate_subgraph(subgraph, seed):
                subgraphs.append(subgraph)
                logger.debug(f"ğŸ¯ Added simple relation-centric subgraph with {len(subgraph.nodes)} nodes")
        
        return subgraphs
    
    def _simple_backward_sampling(self, task_graph: TaskGraph, target_node_id: str, seed: TaskSeedPattern) -> Optional[SubgraphSample]:
        """ç®€åŒ–çš„åå‘é‡‡æ ·"""
        target_node = task_graph.nodes.get(target_node_id)
        if target_node is None:
            return None
        
        sampled_nodes = {target_node_id: target_node}
        sampled_edges = {}
        
        # ç®€å•çš„åå‘BFS
        queue = deque([target_node_id])
        visited = {target_node_id}
        
        while queue and len(sampled_nodes) < self.config.max_nodes:
            current_node_id = queue.popleft()
            
            # é™åˆ¶æ·±åº¦
            if len(visited) > 10:  # é™åˆ¶è®¿é—®çš„èŠ‚ç‚¹æ•°é‡
                break
            
            for edge in task_graph.edges.values():
                if edge.target_node_id == current_node_id and edge.source_node_id not in visited:
                    # ç®€å•çš„è¾¹åŒ…å«åˆ¤æ–­
                    if self._should_include_edge_for_seed(edge, seed, sampled_nodes):
                        sampled_edges[edge.edge_id] = edge
                        source_node = task_graph.nodes.get(edge.source_node_id)
                        if source_node is not None:
                            sampled_nodes[edge.source_node_id] = source_node
                        visited.add(edge.source_node_id)
                        queue.append(edge.source_node_id)
        
        if len(sampled_nodes) >= self.config.min_nodes:
            return SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=target_node_id,
                radius=3,
                strategy=SamplingStrategy.GOAL_CONDITIONED,
                task_seed=seed
            )
        
        return None
    
    def _goal_conditioned_sampling_with_anchors(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                              required_node_types: Set[NodeType]) -> List[SubgraphSample]:
        """å¸¦é”šç‚¹çº¦æŸçš„ç›®æ ‡æ¡ä»¶é‡‡æ ·"""
        subgraphs = []
        
        # æ‰¾åˆ°æ»¡è¶³ç§å­è¦æ±‚çš„èŠ‚ç‚¹
        target_nodes = self._find_nodes_for_seed(task_graph, seed)
        logger.debug(f"ğŸ¯ Found {len(target_nodes)} target nodes for seed {seed.name}")
        
        if not target_nodes:
            return subgraphs
        
        for target_node_id in target_nodes:
            # æ£€æŸ¥ç›®æ ‡èŠ‚ç‚¹æ˜¯å¦åŒ…å«å¿…éœ€çš„é”šç‚¹ç±»å‹
            target_node = task_graph.nodes.get(target_node_id)
            if target_node is None:
                logger.warning(f"ğŸ¯ Target node {target_node_id} is None, skipping")
                continue
            if target_node.node_type in required_node_types:
                logger.debug(f"ğŸ¯ Target node {target_node_id} contains required anchor type {target_node.node_type}")
                
                # æ‰§è¡Œåå‘é‡‡æ ·ï¼Œç¡®ä¿åŒ…å«é”šç‚¹
                subgraph = self._backward_sampling_with_anchors(
                    task_graph, target_node_id, seed, required_node_types
                )
                
                if subgraph and self._validate_subgraph_with_anchors(subgraph, seed, required_node_types):
                    subgraphs.append(subgraph)
                    logger.debug(f"ğŸ¯ Added anchor-validated subgraph with {len(subgraph.nodes)} nodes")
        
        return subgraphs
    
    def _backward_sampling_with_anchors(self, task_graph: TaskGraph, target_node_id: str, 
                                       seed: TaskSeedPattern, required_node_types: Set[NodeType]) -> Optional[SubgraphSample]:
        """å¸¦é”šç‚¹çº¦æŸçš„åå‘é‡‡æ ·"""
        target_node = task_graph.nodes.get(target_node_id)
        if target_node is None:
            logger.warning(f"ğŸ¯ Target node {target_node_id} is None in backward sampling")
            return None
        sampled_nodes = {target_node_id: target_node}
        sampled_edges = {}
        
        # åå‘BFSï¼Œä½†é™åˆ¶è·³æ•°å’Œç±»å‹
        queue = deque([(target_node_id, 0)])
        visited = {target_node_id}
        
        while queue and len(sampled_nodes) < self.config.max_nodes:
            current_node_id, distance = queue.popleft()
            
            # è·³æ•°é™åˆ¶ï¼šæœ€å¤š3è·³
            if distance >= 3:
                continue
            
            for edge in task_graph.edges.values():
                if edge.target_node_id == current_node_id and edge.source_node_id not in visited:
                    # ç²¾å‡†åˆ¤æ–­è¾¹æ˜¯å¦åº”è¯¥è¢«åŒ…å«
                    should_include_edge = self._should_include_edge_for_seed(edge, seed, sampled_nodes)
                    
                    if should_include_edge:
                        sampled_edges[edge.edge_id] = edge
                        source_node = task_graph.nodes.get(edge.source_node_id)
                        if source_node is not None:
                            sampled_nodes[edge.source_node_id] = source_node
                        visited.add(edge.source_node_id)
                        queue.append((edge.source_node_id, distance + 1))
                        
                        logger.debug(f"ğŸ¯ Backward sampling: included edge {edge.edge_id} ({edge.edge_type}) from {edge.source_node_id}")
        
        # åªæœ‰åœ¨é”šç‚¹éªŒè¯å¤±è´¥æ—¶æ‰è¡¥å……é”šç‚¹
        if not self._validate_subgraph_with_anchors(
            SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=target_node_id,
                radius=3,
                strategy=SamplingStrategy.GOAL_CONDITIONED,
                task_seed=seed
            ), seed, required_node_types
        ):
            # é”šç‚¹éªŒè¯å¤±è´¥ï¼Œå°è¯•è¡¥å……ç¼ºå¤±çš„é”šç‚¹
            self._ensure_anchor_nodes_present(task_graph, sampled_nodes, sampled_edges, required_node_types)
            
            # å†æ¬¡éªŒè¯
            if not self._validate_subgraph_with_anchors(
                SubgraphSample(
                    nodes=sampled_nodes,
                    edges=sampled_edges,
                    center_node=target_node_id,
                    radius=3,
                    strategy=SamplingStrategy.GOAL_CONDITIONED,
                    task_seed=seed
                ), seed, required_node_types
            ):
                logger.debug(f"ğŸ¯ Subgraph still invalid after anchor supplementation")
                return None
        
        if len(sampled_nodes) >= self.config.min_nodes:
            return SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=target_node_id,
                radius=3,
                strategy=SamplingStrategy.GOAL_CONDITIONED,
                task_seed=seed
            )
        
        return None
    
    def _does_seed_need_navigation(self, seed: TaskSeedPattern) -> bool:
        """åˆ¤æ–­ç§å­æ˜¯å¦éœ€è¦å¯¼èˆªåŠŸèƒ½"""
        # æ ¹æ®ç§å­åç§°å’Œç±»å‹åˆ¤æ–­æ˜¯å¦éœ€è¦å¯¼èˆª
        seed_name_lower = seed.name.lower()
        seed_type = seed.seed_type
        
        # å¯¼èˆªç›¸å…³çš„å…³é”®è¯
        nav_keywords = ['navigation', 'navigate', 'nav', 'menu', 'link', 'page', 'site']
        
        # æ£€æŸ¥ç§å­åç§°æ˜¯å¦åŒ…å«å¯¼èˆªå…³é”®è¯
        if any(keyword in seed_name_lower for keyword in nav_keywords):
            return True
        
        # æ£€æŸ¥ç§å­ç±»å‹
        if seed_type in [TaskSeedType.BUSINESS_NAVIGATION, TaskSeedType.USER_NAVIGATION, 
                        TaskSeedType.PRODUCT_NAVIGATION, TaskSeedType.ORDER_NAVIGATION, 
                        TaskSeedType.MIXED_DATA_NAVIGATION]:
            return True
        
        return False
    
    def _ensure_anchor_nodes_present(self, task_graph: TaskGraph, sampled_nodes: Dict[str, Any], 
                                    sampled_edges: Dict[str, Any], required_node_types: Set[NodeType], max_attempts: int = 3) -> None:
        """ç¡®ä¿å­å›¾åŒ…å«æ‰€æœ‰å¿…éœ€çš„é”šç‚¹èŠ‚ç‚¹ï¼Œå¸¦å¾ªç¯æ£€æµ‹"""
        # å¾ªç¯æ£€æµ‹ï¼šè®°å½•å°è¯•æ¬¡æ•°
        attempt_count = 0
        
        while attempt_count < max_attempts:
            attempt_count += 1
            current_node_types = {node.node_type for node in sampled_nodes.values() if node is not None}
        
        # å¤„ç†åˆ—è¡¨ç±»å‹çš„é”šç‚¹è¦æ±‚
        processed_required_types = set()
        for anchor_type in required_node_types:
            if isinstance(anchor_type, list):
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œåªè¦æ»¡è¶³å…¶ä¸­ä¸€ç§ç±»å‹å³å¯
                processed_required_types.update(anchor_type)
            else:
                processed_required_types.add(anchor_type)
        
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³é”šç‚¹è¦æ±‚ - æ”¯æŒç±»å‹æ˜ å°„
        missing_anchor_types = set()
        for required_type in processed_required_types:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ»¡è¶³è¯¥ç±»å‹è¦æ±‚
            if required_type not in current_node_types:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å…¼å®¹çš„ç±»å‹å¯ä»¥æ»¡è¶³è¦æ±‚
                    compatible_types = self._get_compatible_node_types(required_type)
                    if not any(compatible_type in current_node_types for compatible_type in compatible_types):
                        missing_anchor_types.add(required_type)
        
            if not missing_anchor_types:
                # æ‰€æœ‰é”šç‚¹è¦æ±‚éƒ½æ»¡è¶³ï¼Œé€€å‡ºå¾ªç¯
                break
            
            logger.debug(f"ğŸ¯ Missing anchor types (attempt {attempt_count}): {missing_anchor_types}")
            
            # å°è¯•æ·»åŠ ç¼ºå¤±çš„é”šç‚¹èŠ‚ç‚¹
            added_any = False
            
            for anchor_type in missing_anchor_types:
                # å¤„ç†åˆ—è¡¨ç±»å‹çš„é”šç‚¹è¦æ±‚
                if isinstance(anchor_type, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ç±»å‹ï¼Œåªè¦æ‰¾åˆ°å…¶ä¸­ä¸€ç§ç±»å‹å³å¯
                    for item_type in anchor_type:
                        anchor_nodes = [node_id for node_id, node in task_graph.nodes.items() 
                                      if node is not None and node.node_type == item_type and node_id not in sampled_nodes]
                        
                        if anchor_nodes:
                            # é€‰æ‹©æœ€æ¥è¿‘çš„é”šç‚¹èŠ‚ç‚¹
                            best_anchor_node = self._find_closest_anchor_node(
                                task_graph, sampled_nodes, anchor_nodes
                            )
                            
                            if best_anchor_node:
                                anchor_node = task_graph.nodes.get(best_anchor_node)
                                if anchor_node is not None:
                                    sampled_nodes[best_anchor_node] = anchor_node
                                logger.debug(f"ğŸ¯ Added missing anchor node {best_anchor_node} (type: {item_type}) from list {anchor_type}")
                                
                                # æ·»åŠ ç›¸å…³çš„è¾¹
                                self._add_anchor_related_edges(task_graph, best_anchor_node, sampled_nodes, sampled_edges)
                                
                                # éªŒè¯è¾¹æ˜¯å¦çœŸæ­£æ·»åŠ æˆåŠŸ
                                logger.debug(f"ğŸ¯ Added anchor node {best_anchor_node} to subgraph")
                                added_any = True
                                
                                # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†ï¼Œè·³å‡ºå†…å±‚å¾ªç¯
                                break
                else:
                    # å•ä¸ªç±»å‹çš„å¤„ç† - æ”¯æŒå…¼å®¹ç±»å‹
                    compatible_types = self._get_compatible_node_types(anchor_type)
                    anchor_nodes = []
                    
                    # ä¼˜å…ˆå¯»æ‰¾ç²¾ç¡®åŒ¹é…çš„ç±»å‹
                    for node_id, node in task_graph.nodes.items():
                        if node is not None and node.node_type == anchor_type and node_id not in sampled_nodes:
                            anchor_nodes.append(node_id)
                    
                    # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå¯»æ‰¾å…¼å®¹ç±»å‹
                    if not anchor_nodes:
                        for compatible_type in compatible_types:
                            if compatible_type != anchor_type:  # é¿å…é‡å¤
                                for node_id, node in task_graph.nodes.items():
                                    if node is not None and node.node_type == compatible_type and node_id not in sampled_nodes:
                                        anchor_nodes.append(node_id)
                    
                    if anchor_nodes:
                        # é€‰æ‹©æœ€æ¥è¿‘çš„é”šç‚¹èŠ‚ç‚¹
                        best_anchor_node = self._find_closest_anchor_node(
                            task_graph, sampled_nodes, anchor_nodes
                        )
                        
                        if best_anchor_node:
                            anchor_node = task_graph.nodes.get(best_anchor_node)
                            if anchor_node is not None:
                                sampled_nodes[best_anchor_node] = anchor_node
                            logger.debug(f"ğŸ¯ Added missing anchor node {best_anchor_node} (type: {anchor_node.node_type if anchor_node else 'unknown'}, compatible with {anchor_type})")
                            
                            # æ·»åŠ ç›¸å…³çš„è¾¹
                            self._add_anchor_related_edges(task_graph, best_anchor_node, sampled_nodes, sampled_edges)
                            
                            # éªŒè¯è¾¹æ˜¯å¦çœŸæ­£æ·»åŠ æˆåŠŸ
                            logger.debug(f"ğŸ¯ Added anchor node {best_anchor_node} to subgraph")
                            added_any = True
            
            # ç§»é™¤ä¸å¯è¾¾çš„èŠ‚ç‚¹
            if sampled_nodes:
                reachable_nodes = self._get_reachable_nodes(sampled_nodes, sampled_edges)
                unreachable_nodes = set(sampled_nodes.keys()) - reachable_nodes
                for node_id in unreachable_nodes:
                    del sampled_nodes[node_id]
                    logger.debug(f"ğŸ¯ Removed unreachable node: {node_id}")
                
                edges_to_remove = []
                for edge_id, edge in sampled_edges.items():
                    if edge.source_node_id not in sampled_nodes or edge.target_node_id not in sampled_nodes:
                        edges_to_remove.append(edge_id)
                
                for edge_id in edges_to_remove:
                    del sampled_edges[edge_id]
                    logger.debug(f"ğŸ¯ Removed orphaned edge: {edge_id}")
            
            # å¦‚æœæ²¡æœ‰æ·»åŠ ä»»ä½•èŠ‚ç‚¹ï¼Œé€€å‡ºå¾ªç¯
            if not added_any:
                logger.warning(f"ğŸ¯ No anchor nodes could be added after attempt {attempt_count}")
                break
        
        # å¾ªç¯ç»“æŸæ£€æŸ¥
        if attempt_count >= max_attempts:
            logger.warning(f"ğŸ¯ Anchor supplementation reached max attempts ({max_attempts})")
    
    def _find_closest_anchor_node(self, task_graph: TaskGraph, sampled_nodes: Dict[str, Any], 
                                 anchor_nodes: List[str]) -> Optional[str]:
        """æ‰¾åˆ°æœ€æ¥è¿‘å·²é‡‡æ ·èŠ‚ç‚¹çš„é”šç‚¹èŠ‚ç‚¹"""
        if not anchor_nodes:
            return None
        
        min_distance = float('inf')
        best_node = None
        
        for anchor_node in anchor_nodes:
            total_distance = 0
            for sampled_node_id in sampled_nodes:
                distance = self._calculate_node_distance(task_graph, anchor_node, sampled_node_id)
                total_distance += distance
            
            if total_distance < min_distance:
                min_distance = total_distance
                best_node = anchor_node
        
        return best_node
    
    def _validate_subgraph_connectivity(self, sampled_nodes: Dict[str, Any], sampled_edges: Dict[str, Any]) -> bool:
        """éªŒè¯å­å›¾çš„è¿é€šæ€§ - æ”¾å®½æ¡ä»¶ï¼Œå…è®¸é”šç‚¹æ¡¥æ¥"""
        if not sampled_nodes:
            return False
        
        if len(sampled_nodes) == 1:
            return True
        
        # æ„å»ºé‚»æ¥è¡¨
        adjacency = {}
        for node_id in sampled_nodes:
            adjacency[node_id] = []
        
        for edge in sampled_edges.values():
            if edge.source_node_id in adjacency and edge.target_node_id in adjacency:
                adjacency[edge.source_node_id].append(edge.target_node_id)
                adjacency[edge.target_node_id].append(edge.source_node_id)
        
        # æ£€æŸ¥è¿é€šæ€§ï¼Œä½†å…è®¸ä¸€äº›èŠ‚ç‚¹é€šè¿‡é”šç‚¹æ¡¥æ¥
        start_node = next(iter(sampled_nodes))
        visited = set()
        queue = deque([start_node])
        visited.add(start_node)
        
        while queue:
            current = queue.popleft()
            for neighbor in adjacency[current]:
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append(neighbor)
        
        # ä¸¥æ ¼è¦æ±‚å®Œå…¨è¿é€šæ€§ï¼Œç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹éƒ½å¯è¾¾
        reachable_ratio = len(visited) / len(sampled_nodes)
        is_fully_connected = reachable_ratio >= 1.0  # è¦æ±‚100%è¿é€š

        logger.debug(f"ğŸ¯ Connectivity check: {len(visited)}/{len(sampled_nodes)} nodes reachable (ratio: {reachable_ratio:.2f})")

        if not is_fully_connected:
            unreachable_nodes = set(sampled_nodes.keys()) - visited
            logger.warning(f"ğŸ¯ Subgraph not fully connected: {len(unreachable_nodes)} unreachable nodes: {list(unreachable_nodes)[:3]}...")
            return False

        return True

    def _ensure_subgraph_reachability(self, sampled_nodes: Dict[str, Any], sampled_edges: Dict[str, Any]) -> bool:
        """ç¡®ä¿å­å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹éƒ½å¯è¾¾ï¼Œå¦‚æœæœ‰ä¸å¯è¾¾èŠ‚ç‚¹åˆ™ç§»é™¤å®ƒä»¬"""
        if not sampled_nodes or len(sampled_nodes) <= 1:
            return True

        # æ„å»ºé‚»æ¥è¡¨
        adjacency = {}
        for node_id in sampled_nodes:
            adjacency[node_id] = []

        for edge in sampled_edges.values():
            if edge.source_node_id in adjacency and edge.target_node_id in adjacency:
                adjacency[edge.source_node_id].append(edge.target_node_id)
                adjacency[edge.target_node_id].append(edge.source_node_id)

        # æ‰¾åˆ°æ‰€æœ‰è¿é€šç»„ä»¶
        visited = set()
        components = []

        for node_id in sampled_nodes:
            if node_id not in visited:
                # å¼€å§‹æ–°çš„è¿é€šç»„ä»¶
                component = set()
                queue = deque([node_id])
                component.add(node_id)
                visited.add(node_id)

                while queue:
                    current = queue.popleft()
                    for neighbor in adjacency[current]:
                        if neighbor not in component:
                            component.add(neighbor)
                            visited.add(neighbor)
                            queue.append(neighbor)

                components.append(component)

        # å¦‚æœåªæœ‰ä¸€ä¸ªè¿é€šç»„ä»¶ï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½å¯è¾¾
        if len(components) == 1:
            return True

        # å¦‚æœæœ‰å¤šä¸ªè¿é€šç»„ä»¶ï¼Œé€‰æ‹©æœ€å¤§çš„ç»„ä»¶ï¼Œç§»é™¤å…¶ä»–ç»„ä»¶
        largest_component = max(components, key=len)
        logger.debug(f"ğŸ¯ Found {len(components)} disconnected components, keeping largest with {len(largest_component)} nodes")

        # ç§»é™¤ä¸åœ¨æœ€å¤§ç»„ä»¶ä¸­çš„èŠ‚ç‚¹
        nodes_to_remove = set(sampled_nodes.keys()) - largest_component
        for node_id in nodes_to_remove:
            del sampled_nodes[node_id]
            logger.debug(f"ğŸ¯ Removed unreachable node: {node_id}")

        # ç§»é™¤ä¸å·²åˆ é™¤èŠ‚ç‚¹ç›¸å…³çš„è¾¹
        edges_to_remove = []
        for edge_id, edge in sampled_edges.items():
            if edge.source_node_id not in sampled_nodes or edge.target_node_id not in sampled_nodes:
                edges_to_remove.append(edge_id)

        for edge_id in edges_to_remove:
            del sampled_edges[edge_id]
            logger.debug(f"ğŸ¯ Removed orphaned edge: {edge_id}")

        # éªŒè¯æ¸…ç†åçš„è¿é€šæ€§
        return self._validate_subgraph_connectivity(sampled_nodes, sampled_edges)

    def _remove_unreachable_nodes(self, sampled_nodes: Dict[str, Any], sampled_edges: Dict[str, Any]) -> None:
        """ç§»é™¤ä¸å¯è¾¾çš„èŠ‚ç‚¹å’Œç›¸å…³çš„è¾¹"""
        if not sampled_nodes:
            return
        
        # æ„å»ºé‚»æ¥è¡¨
        adjacency = {}
        for node_id in sampled_nodes:
            adjacency[node_id] = []
        
        for edge in sampled_edges.values():
            if edge.source_node_id in adjacency and edge.target_node_id in adjacency:
                adjacency[edge.source_node_id].append(edge.target_node_id)
                adjacency[edge.target_node_id].append(edge.source_node_id)
        
        # æ‰¾åˆ°è¿é€šåˆ†é‡
        start_node = next(iter(sampled_nodes))
        visited = set()
        queue = deque([start_node])
        visited.add(start_node)
        
        while queue:
            current = queue.popleft()
            for neighbor in adjacency[current]:
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append(neighbor)
        
        # ç§»é™¤ä¸å¯è¾¾çš„èŠ‚ç‚¹
        unreachable_nodes = set(sampled_nodes.keys()) - visited
        for node_id in unreachable_nodes:
            del sampled_nodes[node_id]
            logger.debug(f"ğŸ¯ Removed unreachable node: {node_id}")
        
        # ç§»é™¤ç›¸å…³çš„è¾¹
        edges_to_remove = []
        for edge_id, edge in sampled_edges.items():
            if edge.source_node_id not in sampled_nodes or edge.target_node_id not in sampled_nodes:
                edges_to_remove.append(edge_id)
        
        for edge_id in edges_to_remove:
            del sampled_edges[edge_id]
            logger.debug(f"ğŸ¯ Removed orphaned edge: {edge_id}")
    
    def _add_anchor_related_edges(self, task_graph: TaskGraph, node_id: str, 
                                 sampled_nodes: Dict[str, Any], sampled_edges: Dict[str, Any]) -> None:
        """æ·»åŠ ä¸é”šç‚¹èŠ‚ç‚¹ç›¸å…³çš„è¾¹"""
        for edge in task_graph.edges.values():
            if (edge.source_node_id == node_id and edge.target_node_id in sampled_nodes) or \
               (edge.target_node_id == node_id and edge.source_node_id in sampled_nodes):
                if edge.edge_id not in sampled_edges:
                    sampled_edges[edge.edge_id] = edge
                    logger.debug(f"ğŸ¯ Added anchor-related edge {edge.edge_id} ({edge.edge_type})")
    
    def _validate_subgraph_with_anchors(self, subgraph: SubgraphSample, seed: TaskSeedPattern, 
                                       required_node_types: Set[NodeType]) -> bool:
        """ç®€åŒ–çš„å­å›¾éªŒè¯ - åªè¿›è¡ŒåŸºç¡€éªŒè¯"""
        # åªè¿›è¡ŒåŸºç¡€éªŒè¯ï¼Œä¸è¿›è¡Œå¤æ‚çš„é”šç‚¹æ£€æŸ¥
        return self._validate_subgraph(subgraph, seed)
    
    def _get_compatible_node_types(self, required_type: NodeType) -> Set[NodeType]:
        """è·å–ä¸æŒ‡å®šç±»å‹å…¼å®¹çš„èŠ‚ç‚¹ç±»å‹"""
        compatible_types = {required_type}  # åŒ…å«è‡ªèº«
        
        # å®šä¹‰ç±»å‹å…¼å®¹æ€§æ˜ å°„
        compatibility_map = {
            NodeType.INPUT: {NodeType.SEARCH_BOX, NodeType.FILTER},
            NodeType.SEARCH_BOX: {NodeType.INPUT, NodeType.FILTER},
            NodeType.FILTER: {NodeType.INPUT, NodeType.SEARCH_BOX},
            NodeType.FORM: {NodeType.INPUT, NodeType.BUTTON, NodeType.SEARCH_BOX},
            NodeType.BUTTON: {NodeType.FORM, NodeType.INPUT},
            NodeType.CONTENT: {NodeType.TABLE, NodeType.LIST, NodeType.CARD, NodeType.DETAIL, NodeType.BUSINESS_DATA, NodeType.USER_DATA, NodeType.PRODUCT_DATA, NodeType.ORDER_DATA},
            NodeType.TABLE: {NodeType.CONTENT, NodeType.LIST, NodeType.BUSINESS_DATA},
            NodeType.LIST: {NodeType.CONTENT, NodeType.TABLE, NodeType.BUSINESS_DATA},
            NodeType.CARD: {NodeType.CONTENT, NodeType.LIST, NodeType.BUSINESS_DATA},
            NodeType.DETAIL: {NodeType.CONTENT, NodeType.BUSINESS_DATA},
            NodeType.NAVIGATION: {NodeType.LINK, NodeType.BUTTON},
            NodeType.LINK: {NodeType.NAVIGATION, NodeType.BUTTON},
            # ä¸šåŠ¡æ•°æ®ç±»å‹ä¹‹é—´çš„å…¼å®¹æ€§
            NodeType.BUSINESS_DATA: {NodeType.CONTENT, NodeType.TABLE, NodeType.LIST, NodeType.CARD, NodeType.DETAIL},
            NodeType.USER_DATA: {NodeType.BUSINESS_DATA, NodeType.CONTENT},
            NodeType.PRODUCT_DATA: {NodeType.BUSINESS_DATA, NodeType.CONTENT},
            NodeType.ORDER_DATA: {NodeType.BUSINESS_DATA, NodeType.CONTENT},
        }
        
        if required_type in compatibility_map:
            compatible_types.update(compatibility_map[required_type])
        
        return compatible_types
    
    def _get_reachable_nodes(self, nodes: Dict[str, Any], edges: Dict[str, Any]) -> Set[str]:
        """è·å–ä»é”šç‚¹å¯è¾¾çš„æ‰€æœ‰èŠ‚ç‚¹"""
        if not nodes or not edges:
            return set(nodes.keys()) if nodes else set()
        
        # æ‰¾åˆ°æ‰€æœ‰é”šç‚¹ï¼ˆé€šå¸¸æ˜¯INPUT, BUTTON, FORMç­‰å…³é”®èŠ‚ç‚¹ï¼‰
        anchor_nodes = set()
        for node_id, node in nodes.items():
            if hasattr(node, 'node_type') and node.node_type in [
                NodeType.INPUT, NodeType.BUTTON, NodeType.FORM, 
                NodeType.NAVIGATION, NodeType.SEARCH_BOX
            ]:
                anchor_nodes.add(node_id)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é”šç‚¹ï¼Œè¿”å›æ‰€æœ‰èŠ‚ç‚¹
        if not anchor_nodes:
            return set(nodes.keys())
        
        # ä»é”šç‚¹å¼€å§‹BFSï¼Œæ‰¾åˆ°æ‰€æœ‰å¯è¾¾èŠ‚ç‚¹
        reachable = set()
        queue = list(anchor_nodes)
        
        while queue:
            current_node = queue.pop(0)
            if current_node in reachable:
                continue
                
            reachable.add(current_node)
            
            # æ‰¾åˆ°ä¸å½“å‰èŠ‚ç‚¹ç›¸è¿çš„æ‰€æœ‰è¾¹
            for edge_id, edge in edges.items():
                if edge.source_node_id == current_node and edge.target_node_id in nodes:
                    if edge.target_node_id not in reachable:
                        queue.append(edge.target_node_id)
                elif edge.target_node_id == current_node and edge.source_node_id in nodes:
                    if edge.source_node_id not in reachable:
                        queue.append(edge.source_node_id)
        
        return reachable
    
    def _enhanced_validation_and_deduplication(self, subgraphs: List[SubgraphSample]) -> List[SubgraphSample]:
        """å¢å¼ºéªŒè¯å’Œå»é‡ - ç§»é™¤è¿‡åº¦ä¸¥æ ¼çš„å…ƒè·¯å¾„å»é‡"""
        if not subgraphs:
            return []
        
        # 1. åŸºç¡€éªŒè¯
        valid_subgraphs = []
        for subgraph in subgraphs:
            if subgraph.task_seed and self._validate_subgraph(subgraph, subgraph.task_seed):
                valid_subgraphs.append(subgraph)
        
        logger.info(f"ğŸ¯ Enhanced validation: {len(subgraphs)} -> {len(valid_subgraphs)} valid subgraphs")
        
        # 2. ç›´æ¥ä½¿ç”¨å®½æ¾å»é‡ï¼Œé¿å…è¿‡åº¦å»é‡é—®é¢˜
        unique_subgraphs = self._relaxed_deduplication(valid_subgraphs, self.config.max_total_subgraphs)
        logger.info(f"ğŸ¯ Relaxed deduplication: {len(valid_subgraphs)} -> {len(unique_subgraphs)} unique subgraphs")
        
        return unique_subgraphs
    
    
    def _relaxed_deduplication(self, subgraphs: List[SubgraphSample], max_subgraphs: int = 200) -> List[SubgraphSample]:
        """å®½æ¾å»é‡ - å½“ä¸¥æ ¼å»é‡ç»“æœå¤ªå°‘æ—¶ä½¿ç”¨ï¼Œæ”¯æŒå†…å®¹å¤šæ ·æ€§"""
        if not subgraphs:
            return []
        
        unique_subgraphs = []
        seen_basic_patterns = set()
        seen_content_patterns = set()
        
        for subgraph in subgraphs:
            # 1. åŸºæœ¬èŠ‚ç‚¹ç±»å‹æ¨¡å¼
            basic_pattern = "->".join(sorted([node.node_type.value for node in subgraph.nodes.values() if node is not None]))
            
            # 2. å†…å®¹æ¨¡å¼ï¼ˆåŸºäºèŠ‚ç‚¹å†…å®¹ï¼‰
            content_pattern = self._generate_content_pattern(subgraph)
            
            # 3. å†³å®šæ˜¯å¦ä¿ç•™å­å›¾
            should_keep = False
            
            # å¦‚æœåŸºæœ¬æ¨¡å¼æ²¡è§è¿‡ï¼Œä¿ç•™
            if basic_pattern not in seen_basic_patterns:
                should_keep = True
                seen_basic_patterns.add(basic_pattern)
                logger.debug(f"ğŸ¯ Relaxed deduplication: new basic pattern {basic_pattern}")
            
            # å¦‚æœå†…å®¹æ¨¡å¼æ²¡è§è¿‡ï¼Œä¹Ÿä¿ç•™ï¼ˆå³ä½¿åŸºæœ¬æ¨¡å¼ç›¸åŒï¼‰
            elif content_pattern not in seen_content_patterns:
                should_keep = True
                seen_content_patterns.add(content_pattern)
                logger.debug(f"ğŸ¯ Relaxed deduplication: new content pattern for {basic_pattern}")
            
            # å¦‚æœå­å›¾æ•°é‡è¿˜å¾ˆå°‘ï¼Œä¹Ÿä¿ç•™
            elif len(unique_subgraphs) < max_subgraphs:  # ä½¿ç”¨é…ç½®ä¸­çš„æ•°é‡é™åˆ¶
                should_keep = True
                logger.debug(f"ğŸ¯ Relaxed deduplication: keeping for diversity (count: {len(unique_subgraphs)})")
            
            if should_keep:
                unique_subgraphs.append(subgraph)
        
        logger.info(f"ğŸ¯ Relaxed deduplication: {len(subgraphs)} -> {len(unique_subgraphs)} subgraphs")
        return unique_subgraphs
    
    def _generate_content_pattern(self, subgraph: SubgraphSample) -> str:
        """ç”ŸæˆåŸºäºèŠ‚ç‚¹å†…å®¹çš„æ¨¡å¼ï¼Œç”¨äºå†…å®¹å¤šæ ·æ€§æ£€æµ‹"""
        if not subgraph.nodes:
            return ""
        
        content_signatures = []
        for node_id, node in subgraph.nodes.items():
            if node is None:
                continue
            
            # æå–èŠ‚ç‚¹çš„å†…å®¹ç­¾å
            content_parts = []
            
            # æ–‡æœ¬å†…å®¹
            if hasattr(node, 'text_content') and node.text_content:
                content_parts.append(f"text:{node.text_content[:50]}")
            elif hasattr(node, 'text') and node.text:
                content_parts.append(f"text:{node.text[:50]}")
            
            # å€¼å†…å®¹
            if hasattr(node, 'value') and node.value:
                content_parts.append(f"value:{str(node.value)[:50]}")
            
            # å±æ€§å†…å®¹
            if hasattr(node, 'properties') and node.properties:
                for key, value in node.properties.items():
                    if value and len(str(value)) > 0:
                        content_parts.append(f"{key}:{str(value)[:30]}")
            
            # å¦‚æœæœ‰å†…å®¹ï¼Œæ·»åŠ åˆ°ç­¾åä¸­
            if content_parts:
                content_signatures.append(f"{node_id}:{'|'.join(content_parts)}")
        
        return "||".join(content_signatures)
    
    def _sort_by_executability_score(self, subgraphs: List[SubgraphSample]) -> List[SubgraphSample]:
        """æŒ‰å¯æ‰§è¡Œæ€§åˆ†æ•°æ’åº"""
        if not subgraphs:
            return []
        
        # è®¡ç®—æ¯ä¸ªå­å›¾çš„å¯æ‰§è¡Œæ€§åˆ†æ•°
        scored_subgraphs = []
        for subgraph in subgraphs:
            score = self._calculate_executability_score(subgraph)
            scored_subgraphs.append((subgraph, score))
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        scored_subgraphs.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›æ’åºåçš„å­å›¾
        sorted_subgraphs = [subgraph for subgraph, score in scored_subgraphs]
        
        logger.info(f"ğŸ¯ Sorted {len(sorted_subgraphs)} subgraphs by executability score")
        return sorted_subgraphs
    
    def _calculate_executability_score(self, subgraph: SubgraphSample) -> float:
        """è®¡ç®—å­å›¾çš„å¯æ‰§è¡Œæ€§åˆ†æ•° - ä¼˜å…ˆé€‰æ‹©ç»“æ„å®Œæ•´ã€åŠŸèƒ½ä¸°å¯Œçš„å­å›¾"""
        score = 0.0
        
        # 1. ä¸šåŠ¡æ•°æ®è¦†ç›–åº¦åˆ†æ•°ï¼ˆæƒé‡æœ€é«˜ï¼‰
        business_data_nodes = [node for node in subgraph.nodes.values() 
                             if node is not None and node.node_type in {NodeType.BUSINESS_DATA, NodeType.USER_DATA, 
                                                  NodeType.PRODUCT_DATA, NodeType.ORDER_DATA}]
        score += len(business_data_nodes) * 3.0  # æé«˜æƒé‡
        
        # 2. åŠŸèƒ½æ¨¡å—å¤šæ ·æ€§åˆ†æ•°ï¼ˆæ–°å¢ï¼‰
        node_types = {node.node_type for node in subgraph.nodes.values() if node is not None}
        functional_modules = {
            NodeType.SEARCH_BOX, NodeType.INPUT, NodeType.FORM,  # è¾“å…¥æ¨¡å—
            NodeType.BUTTON, NodeType.LINK, NodeType.NAVIGATION,  # äº¤äº’æ¨¡å—
            NodeType.TABLE, NodeType.RESULT_ITEM, NodeType.CONTENT_DATA,  # å±•ç¤ºæ¨¡å—
            NodeType.BUSINESS_DATA, NodeType.USER_DATA, NodeType.PRODUCT_DATA, NodeType.ORDER_DATA  # æ•°æ®æ¨¡å—
        }
        module_coverage = len(node_types.intersection(functional_modules))
        score += module_coverage * 2.0  # åŠŸèƒ½æ¨¡å—è¶Šå¤šåˆ†æ•°è¶Šé«˜
        
        # 3. èŠ‚ç‚¹å¯ç”¨æ€§åˆ†æ•°
        for node in subgraph.nodes.values():
            if node is None:
                continue
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„label/value
            if hasattr(node, 'text') and node.text and node.text.strip():
                score += 1.0
            if hasattr(node, 'value') and node.value:
                score += 1.0
        
        # 4. ç»“æ„å®Œæ•´æ€§åˆ†æ•°ï¼ˆæé«˜æƒé‡ï¼‰
        if len(subgraph.nodes) >= 4:  # æé«˜èŠ‚ç‚¹æ•°é‡è¦æ±‚
            score += 5.0  # åŸºç¡€ç»“æ„åˆ†
        elif len(subgraph.nodes) >= 3:
            score += 3.0
        if len(subgraph.edges) >= 3:  # æé«˜è¾¹æ•°é‡è¦æ±‚
            score += 4.0  # è¿æ¥æ€§åˆ†
        elif len(subgraph.edges) >= 2:
            score += 2.0
        
        # 5. äº¤äº’å…ƒç´ ä¸°å¯Œåº¦åˆ†æ•°ï¼ˆæ–°å¢ï¼‰
        interactive_nodes = [node for node in subgraph.nodes.values() 
                           if node is not None and node.node_type in {NodeType.BUTTON, NodeType.LINK, NodeType.NAVIGATION, NodeType.SEARCH_BOX, NodeType.INPUT}]
        score += len(interactive_nodes) * 2.0  # äº¤äº’å…ƒç´ è¶Šå¤šåˆ†æ•°è¶Šé«˜
        
        # 6. è¾¹ç±»å‹å¤šæ ·æ€§åˆ†æ•°ï¼ˆæ–°å¢ï¼‰
        edge_types = {edge.edge_type for edge in subgraph.edges.values()}
        score += len(edge_types) * 1.5  # è¾¹ç±»å‹è¶Šå¤šåˆ†æ•°è¶Šé«˜
        
        # 7. ä¸šåŠ¡é€»è¾‘å®Œæ•´æ€§å¥–åŠ±ï¼ˆæ–°å¢ï¼‰
        # å¦‚æœåŒæ—¶åŒ…å«è¾“å…¥ã€äº¤äº’ã€æ•°æ®ã€å±•ç¤ºç­‰æ¨¡å—ï¼Œç»™äºˆé¢å¤–å¥–åŠ±
        if (NodeType.SEARCH_BOX in node_types or NodeType.INPUT in node_types) and \
           (NodeType.BUTTON in node_types or NodeType.LINK in node_types) and \
           (NodeType.BUSINESS_DATA in node_types or NodeType.USER_DATA in node_types or NodeType.PRODUCT_DATA in node_types):
            score += 5.0  # å®Œæ•´çš„ä¸šåŠ¡é€»è¾‘å¥–åŠ±
        
        logger.debug(f"ğŸ¯ Enhanced executability score for subgraph: {score}")
        return score
    
    # ==================== è¡¥å……ç¼ºå¤±çš„é”šç‚¹é‡‡æ ·æ–¹æ³• ====================
    
    def _element_centric_sampling_with_anchors(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                              required_node_types: Set[NodeType]) -> List[SubgraphSample]:
        """ä¼˜åŒ–çš„å…ƒç´ ä¸­å¿ƒé‡‡æ · - æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©å’Œæ‰©å±•"""
        subgraphs = []
        
        # 1. ä¼˜å…ˆå¯»æ‰¾èƒ½ç›´æ¥æ»¡è¶³æ‰€æœ‰é”šç‚¹è¦æ±‚çš„èŠ‚ç‚¹ç»„åˆ
        complete_anchor_sets = self._find_anchor_complete_node_sets(task_graph, seed, required_node_types)
        
        if complete_anchor_sets:
            logger.debug(f"ğŸ¯ Found {len(complete_anchor_sets)} complete anchor sets for {seed.name}")
            
            # ä½¿ç”¨å®Œæ•´çš„é”šç‚¹ç»„åˆè¿›è¡Œé‡‡æ ·
            for anchor_set in complete_anchor_sets[:3]:  # æœ€å¤šå°è¯•3ä¸ªç»„åˆ
                subgraph = self._sample_from_anchor_set(task_graph, anchor_set, seed, required_node_types)
                if subgraph and self._validate_subgraph_with_anchors(subgraph, seed, required_node_types):
                    subgraphs.append(subgraph)
                    logger.debug(f"ğŸ¯ Added subgraph from complete anchor set: {len(subgraph.nodes)} nodes")
                    
                    if len(subgraphs) >= 3:  # é™åˆ¶æ•°é‡
                        break
        
        # 2. å¦‚æœå®Œæ•´é”šç‚¹ç»„åˆä¸å¤Ÿï¼Œä½¿ç”¨ä¼ ç»Ÿçš„å•èŠ‚ç‚¹é‡‡æ ·
        if len(subgraphs) < 2:
            logger.debug(f"ğŸ¯ Falling back to traditional single-node sampling for {seed.name}")
            candidate_nodes = self._find_smart_candidate_nodes(task_graph, seed, required_node_types)
            logger.debug(f"ğŸ¯ Found {len(candidate_nodes)} smart candidate nodes")
            
            max_attempts = min(len(candidate_nodes), 10)  # å‡å°‘å°è¯•æ¬¡æ•°
            
            for i, center_node_id in enumerate(candidate_nodes[:max_attempts]):
                center_node = task_graph.nodes.get(center_node_id)
                if center_node is None:
                    continue
            
                # å¿«é€Ÿé¢„æ£€æŸ¥ï¼šèŠ‚ç‚¹æ˜¯å¦æ»¡è¶³åŸºæœ¬è¦æ±‚
                if not self._quick_node_check(center_node, seed, required_node_types):
                    continue
                
                subgraph = self._optimized_bfs_sampling(
                    task_graph, center_node_id, seed, required_node_types
                )
                
                if subgraph and self._validate_subgraph_with_anchors(subgraph, seed, required_node_types):
                    subgraphs.append(subgraph)
                    logger.debug(f"ğŸ¯ Added optimized subgraph with {len(subgraph.nodes)} nodes from {center_node_id}")
            
                    # 5. é™åˆ¶å­å›¾æ•°é‡ï¼Œé¿å…è¿‡åº¦é‡‡æ ·
                    if len(subgraphs) >= 10:  # æ¯ä¸ªç§å­æœ€å¤š10ä¸ªå­å›¾
                        break
        
        logger.info(f"ğŸ¯ Element-centric sampling completed: {len(subgraphs)} subgraphs for {seed.name}")
        return subgraphs
    
    def _find_smart_candidate_nodes(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                   required_node_types: Set[NodeType]) -> List[str]:
        """æ™ºèƒ½é€‰æ‹©å€™é€‰èŠ‚ç‚¹ - ä¼˜å…ˆé€‰æ‹©èƒ½ç›´æ¥æ»¡è¶³é”šç‚¹è¦æ±‚çš„èŠ‚ç‚¹ç»„åˆ"""
        candidates = []
        
        # 1. ä¼˜å…ˆé€‰æ‹©åŒ…å«å¿…éœ€é”šç‚¹ç±»å‹çš„èŠ‚ç‚¹
        for node_id, node in task_graph.nodes.items():
            if node is None:
                continue
                
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…éœ€çš„é”šç‚¹ç±»å‹
            if node.node_type in required_node_types:
                candidates.append(node_id)
                continue
            
            # 2. æ ¹æ®ç§å­ç±»å‹é€‰æ‹©ç›¸å…³èŠ‚ç‚¹
            if self._is_node_relevant_for_seed(node, seed):
                candidates.append(node_id)
        
        # 3. æŒ‰ç›¸å…³æ€§æ’åº
        candidates.sort(key=lambda node_id: self._calculate_node_relevance(
            task_graph.nodes[node_id], seed, required_node_types
        ), reverse=True)
        
        return candidates
    
    def _find_anchor_complete_node_sets(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                       required_node_types: Set[NodeType]) -> List[List[str]]:
        """å¯»æ‰¾èƒ½ç›´æ¥æ»¡è¶³æ‰€æœ‰é”šç‚¹è¦æ±‚çš„èŠ‚ç‚¹ç»„åˆï¼Œé¿å…åç»­è¡¥å……"""
        # æŒ‰ç±»å‹åˆ†ç»„æ‰€æœ‰èŠ‚ç‚¹
        nodes_by_type = {}
        for node_id, node in task_graph.nodes.items():
            if node is None:
                continue
            node_type = node.node_type
            if node_type not in nodes_by_type:
                nodes_by_type[node_type] = []
            nodes_by_type[node_type].append(node_id)
        
        # å¯»æ‰¾èƒ½è¦†ç›–æ‰€æœ‰å¿…éœ€ç±»å‹çš„èŠ‚ç‚¹ç»„åˆ
        complete_sets = []
        
        # å¯¹äºæ¯ä¸ªå¿…éœ€çš„ç±»å‹ï¼Œæ‰¾åˆ°å¯¹åº”çš„èŠ‚ç‚¹
        for required_type in required_node_types:
            compatible_types = self._get_compatible_node_types(required_type)
            available_nodes = []
            
            for compatible_type in compatible_types:
                if compatible_type in nodes_by_type:
                    available_nodes.extend(nodes_by_type[compatible_type])
            
            if not available_nodes:
                logger.debug(f"ğŸ¯ No nodes found for required type {required_type}")
                return []  # å¦‚æœæŸä¸ªå¿…éœ€ç±»å‹æ²¡æœ‰å¯¹åº”èŠ‚ç‚¹ï¼Œè¿”å›ç©ºåˆ—è¡¨
        
        # ç”ŸæˆèŠ‚ç‚¹ç»„åˆï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼šé€‰æ‹©æ¯ä¸ªç±»å‹çš„ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼‰
        node_combination = []
        for required_type in required_node_types:
            compatible_types = self._get_compatible_node_types(required_type)
            for compatible_type in compatible_types:
                if compatible_type in nodes_by_type and nodes_by_type[compatible_type]:
                    node_combination.append(nodes_by_type[compatible_type][0])
                    break
        
        if len(node_combination) >= len(required_node_types):
            complete_sets.append(node_combination)
            logger.debug(f"ğŸ¯ Found complete anchor set: {node_combination}")
        
        return complete_sets
    
    def _sample_from_anchor_set(self, task_graph: TaskGraph, anchor_set: List[str], 
                               seed: TaskSeedPattern, required_node_types: Set[NodeType]) -> Optional[SubgraphSample]:
        """ä»å®Œæ•´çš„é”šç‚¹é›†åˆå¼€å§‹é‡‡æ ·å­å›¾"""
        if not anchor_set:
            return None
        
        # åˆå§‹åŒ–å­å›¾
        sampled_nodes = {}
        sampled_edges = {}
        
        # æ·»åŠ æ‰€æœ‰é”šç‚¹èŠ‚ç‚¹
        for node_id in anchor_set:
            node = task_graph.nodes.get(node_id)
            if node is not None:
                sampled_nodes[node_id] = node
        
        # æ·»åŠ é”šç‚¹ä¹‹é—´çš„è¾¹
        for edge in task_graph.edges.values():
            if edge.source_node_id in sampled_nodes and edge.target_node_id in sampled_nodes:
                sampled_edges[edge.edge_id] = edge
        
        # ä»é”šç‚¹é›†åˆæ‰©å±•ï¼Œå¯»æ‰¾ç›¸å…³èŠ‚ç‚¹
        queue = list(anchor_set)
        visited = set(anchor_set)
        
        while queue and len(sampled_nodes) < self.config.max_nodes:
            current_node_id = queue.pop(0)
            
            # å¯»æ‰¾ç›¸é‚»èŠ‚ç‚¹
            for edge in task_graph.edges.values():
                if edge.source_node_id == current_node_id and edge.target_node_id not in visited:
                    neighbor_id = edge.target_node_id
                    neighbor_node = task_graph.nodes.get(neighbor_id)
                    
                    if neighbor_node is not None:
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥åŒ…å«è¿™ä¸ªé‚»å±…èŠ‚ç‚¹
                        if self._should_include_neighbor(neighbor_node, seed, required_node_types):
                            sampled_nodes[neighbor_id] = neighbor_node
                            sampled_edges[edge.edge_id] = edge
                            queue.append(neighbor_id)
                            visited.add(neighbor_id)
                
                elif edge.target_node_id == current_node_id and edge.source_node_id not in visited:
                    neighbor_id = edge.source_node_id
                    neighbor_node = task_graph.nodes.get(neighbor_id)
                    
                    if neighbor_node is not None:
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥åŒ…å«è¿™ä¸ªé‚»å±…èŠ‚ç‚¹
                        if self._should_include_neighbor(neighbor_node, seed, required_node_types):
                            sampled_nodes[neighbor_id] = neighbor_node
                            sampled_edges[edge.edge_id] = edge
                            queue.append(neighbor_id)
                            visited.add(neighbor_id)
        
        # éªŒè¯è¿é€šæ€§
        if not self._validate_subgraph_connectivity(sampled_nodes, sampled_edges):
            logger.debug(f"ğŸ¯ Subgraph from anchor set failed connectivity validation")
            return None
        
        if len(sampled_nodes) >= self.config.min_nodes:
            return SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=anchor_set[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªé”šç‚¹ä½œä¸ºä¸­å¿ƒèŠ‚ç‚¹
                strategy=SamplingStrategy.ELEMENT_CENTRIC
            )
        
        return None
    
    def _should_include_neighbor(self, neighbor_node: Any, seed: TaskSeedPattern, 
                               required_node_types: Set[NodeType]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åŒ…å«é‚»å±…èŠ‚ç‚¹"""
        if neighbor_node is None:
            return False
        
        # ä¼˜å…ˆåŒ…å«å¿…éœ€ç±»å‹çš„èŠ‚ç‚¹
        if neighbor_node.node_type in required_node_types:
            return True
        
        # åŒ…å«ä¸ç§å­ç›¸å…³çš„èŠ‚ç‚¹
        if self._is_node_relevant_for_seed(neighbor_node, seed):
            return True
        
        # å¢å¼ºä¸šåŠ¡æ•°æ®èŠ‚ç‚¹å¤„ç†ï¼ˆå¯¹äºä¸šåŠ¡ç§å­ï¼‰
        seed_category = getattr(seed, 'seed_category', 'interaction')
        if seed_category == "business":
            # ç›´æ¥åŒ¹é…ä¸šåŠ¡æ•°æ®ç±»å‹
            business_types = {
                NodeType.BUSINESS_DATA, NodeType.USER_DATA, NodeType.PRODUCT_DATA,
                NodeType.ORDER_DATA, NodeType.CONTENT_DATA, NodeType.FINANCIAL_DATA,
                NodeType.LOCATION_DATA, NodeType.TIME_DATA
            }
            if neighbor_node.node_type in business_types:
                return True

            # æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«ä¸šåŠ¡å…³é”®è¯ï¼ˆé’ˆå¯¹SuiteCRMç­‰ç³»ç»Ÿï¼‰
            text_content = getattr(neighbor_node.metadata, 'text_content', '').lower()
            business_keywords = [
                'account', 'contact', 'lead', 'opportunity', 'quote', 'invoice',
                'product', 'campaign', 'report', 'dashboard', 'calendar', 'meeting',
                'task', 'call', 'email', 'note', 'document', 'project'
            ]
            if any(keyword in text_content for keyword in business_keywords):
                return True

        return False
    
    def _is_node_relevant_for_seed(self, node: Any, seed: TaskSeedPattern) -> bool:
        """åˆ¤æ–­èŠ‚ç‚¹æ˜¯å¦ä¸ç§å­ç›¸å…³"""
        if node is None:
            return False
        seed_name_lower = seed.name.lower()
        node_type = node.node_type.value.lower()
        
        # æ ¹æ®ç§å­åç§°åŒ¹é…ç›¸å…³èŠ‚ç‚¹ç±»å‹
        if 'search' in seed_name_lower and node_type in ['search_box', 'input', 'button']:
            return True
        elif 'form' in seed_name_lower and node_type in ['form', 'input', 'button', 'submit']:
            return True
        elif 'navigation' in seed_name_lower and node_type in ['navigation', 'link', 'button', 'menu']:
            return True
        elif 'data' in seed_name_lower and node_type in ['business_data', 'content', 'table', 'user_data', 'product_data', 'order_data']:
            return True
        elif 'comparison' in seed_name_lower and node_type in ['content', 'table', 'card', 'business_data']:
            return True
        elif 'business' in seed_name_lower and node_type in ['business_data', 'user_data', 'product_data', 'order_data', 'navigation', 'menu']:
            return True
        
        return False
    
    def _calculate_node_relevance(self, node: Any, seed: TaskSeedPattern, 
                                 required_node_types: Set[NodeType]) -> float:
        """è®¡ç®—èŠ‚ç‚¹ä¸ç§å­çš„ç›¸å…³æ€§åˆ†æ•°"""
        if node is None:
            return 0.0
        score = 0.0
        
        # 1. é”šç‚¹ç±»å‹åŒ¹é…
        if node.node_type in required_node_types:
            score += 10.0
        
        # 2. ç§å­ç±»å‹åŒ¹é…
        if self._is_node_relevant_for_seed(node, seed):
            score += 5.0
        
        # 3. èŠ‚ç‚¹ç±»å‹é‡è¦æ€§
        high_importance_types = {'business_data', 'form', 'input', 'button', 'navigation'}
        if node.node_type.value.lower() in high_importance_types:
            score += 3.0

        # 4. ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹é¢å¤–åŠ åˆ†
        business_types = {'business_data', 'user_data', 'product_data', 'order_data', 'content_data'}
        if node.node_type.value.lower() in business_types:
            score += 4.0  # ä¸šåŠ¡æ•°æ®èŠ‚ç‚¹æ›´é«˜ä¼˜å…ˆçº§

        # 5. å†…å®¹ç›¸å…³æ€§ï¼ˆé’ˆå¯¹SuiteCRMç­‰ç³»ç»Ÿï¼‰
        text_content = getattr(node.metadata if hasattr(node, 'metadata') else node, 'text_content', '').lower()
        seed_category = getattr(seed, 'seed_category', 'interaction')

        if seed_category == 'business':
            business_keywords = [
                'account', 'contact', 'lead', 'opportunity', 'quote', 'invoice',
                'product', 'campaign', 'report', 'dashboard', 'calendar', 'meeting'
            ]
            if any(keyword in text_content for keyword in business_keywords):
                score += 2.0
        
        return score
    
    def _quick_node_check(self, node: Any, seed: TaskSeedPattern, 
                         required_node_types: Set[NodeType]) -> bool:
        """å¿«é€ŸèŠ‚ç‚¹æ£€æŸ¥ - é¿å…å¤æ‚çš„éªŒè¯é€»è¾‘"""
        if node is None:
            return False
        # åŸºæœ¬æ£€æŸ¥ï¼šèŠ‚ç‚¹ç±»å‹æ˜¯å¦åŒ¹é…
        if node.node_type in required_node_types:
            return True
        
        # å¿«é€Ÿç›¸å…³æ€§æ£€æŸ¥
        if self._is_node_relevant_for_seed(node, seed):
            return True
        
        return False
    
    def _optimized_bfs_sampling(self, task_graph: TaskGraph, center_node_id: str, 
                               seed: TaskSeedPattern, required_node_types: Set[NodeType]) -> Optional[SubgraphSample]:
        """ä¼˜åŒ–çš„BFSé‡‡æ · - æ›´æ™ºèƒ½çš„æ‰©å±•ç­–ç•¥"""
        sampled_nodes = {center_node_id: task_graph.nodes[center_node_id]}
        sampled_edges = {}
        queue = deque([center_node_id])
        visited = {center_node_id}
        
        # é™åˆ¶BFSæ·±åº¦å’Œå®½åº¦ï¼Œæé«˜æ•ˆç‡
        max_depth = 3
        max_nodes = self.config.max_nodes
        current_depth = 0
        
        while queue and len(sampled_nodes) < max_nodes and current_depth < max_depth:
            current_level_size = len(queue)
            current_depth += 1
            
            for _ in range(current_level_size):
                if not queue:
                    break
                    
                current_node_id = queue.popleft()
                
                # æ™ºèƒ½æ‰©å±•ï¼šä¼˜å…ˆé€‰æ‹©ç›¸å…³è¾¹
                relevant_edges = self._find_relevant_edges(
                    task_graph, current_node_id, seed, required_node_types
                )
                
                # åŠ¨æ€è°ƒæ•´æ‰©å±•æ•°é‡ï¼šä¼˜å…ˆé€‰æ‹©é«˜è´¨é‡è¾¹ï¼Œç¡®ä¿å¯è¾¾æ€§
                max_expansions = 2 if len(sampled_nodes) < max_nodes // 2 else 1  # å‰åŠéƒ¨åˆ†å…è®¸æ›´å¤šæ‰©å±•

                for edge in relevant_edges[:max_expansions]:
                    neighbor_id = edge.target_node_id if edge.source_node_id == current_node_id else edge.source_node_id

                    if neighbor_id not in visited and len(sampled_nodes) < max_nodes:
                        visited.add(neighbor_id)
                        sampled_nodes[neighbor_id] = task_graph.nodes[neighbor_id]
                        sampled_edges[edge.edge_id] = edge
                        queue.append(neighbor_id)

                        # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›åŠŸèƒ½æ€§è¿æ¥
                        if len([e for e in sampled_edges.values() if e.edge_type.value.lower() in ['controls', 'fills', 'opens']]) == 0:
                            # å¦‚æœè¿˜æ²¡æœ‰åŠŸèƒ½æ€§è¾¹ï¼Œç»§ç»­å¯»æ‰¾
                            break
        
        # ç¡®ä¿åŒ…å«å¿…éœ€çš„é”šç‚¹
        self._ensure_anchor_nodes_present(task_graph, sampled_nodes, sampled_edges, required_node_types)

        # ç¡®ä¿å­å›¾çš„å¯è¾¾æ€§ï¼Œç§»é™¤ä¸å¯è¾¾çš„èŠ‚ç‚¹
        if not self._ensure_subgraph_reachability(sampled_nodes, sampled_edges):
            logger.debug(f"ğŸ¯ Failed to ensure subgraph reachability for center node {center_node_id}")
            return None

        if len(sampled_nodes) >= 2:  # è‡³å°‘éœ€è¦2ä¸ªèŠ‚ç‚¹
            return SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=center_node_id,
                strategy=SamplingStrategy.ELEMENT_CENTRIC
            )
        
        return None
    
    def _find_relevant_edges(self, task_graph: TaskGraph, node_id: str,
                            seed: TaskSeedPattern, required_node_types: Set[NodeType]) -> List[Any]:
        """æ‰¾åˆ°ä¸èŠ‚ç‚¹ç›¸å…³çš„è¾¹ - å¢å¼ºå¯è¾¾æ€§ä¿è¯"""
        relevant_edges = []

        for edge in task_graph.edges.values():
            if edge.source_node_id == node_id or edge.target_node_id == node_id:
                neighbor_id = edge.target_node_id if edge.source_node_id == node_id else edge.source_node_id

                # æ£€æŸ¥é‚»å±…èŠ‚ç‚¹æ˜¯å¦åœ¨å›¾ä¸­å­˜åœ¨
                if neighbor_id not in task_graph.nodes:
                    continue

                # ä¼˜å…ˆçº§æ’åºï¼šåŠŸèƒ½æ€§è¾¹ > ç»“æ„è¾¹ > å…¶ä»–è¾¹
                edge_type = edge.edge_type.value.lower()
                if edge_type in ['controls', 'fills', 'opens', 'nav_to']:
                    # åŠŸèƒ½æ€§è¾¹ï¼šæœ€é«˜ä¼˜å…ˆçº§ï¼Œç¡®ä¿äº¤äº’å¯è¾¾æ€§
                    relevant_edges.append((edge, 4, 'functional'))
                elif edge_type == 'contains':
                    # åŒ…å«è¾¹ï¼šä¸­ç­‰ä¼˜å…ˆçº§ï¼Œç¡®ä¿ç»“æ„å®Œæ•´æ€§
                    relevant_edges.append((edge, 3, 'structural'))
                elif edge_type in ['refers_to', 'same_entity', 'supports_fact']:
                    # è¯­ä¹‰è¾¹ï¼šä¸­ç­‰ä¼˜å…ˆçº§ï¼Œç¡®ä¿è¯­ä¹‰è¿é€šæ€§
                    relevant_edges.append((edge, 2, 'semantic'))
                else:
                    # å…¶ä»–è¾¹ï¼šæœ€ä½ä¼˜å…ˆçº§
                    relevant_edges.append((edge, 1, 'other'))

        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œç¡®ä¿é«˜è´¨é‡è¾¹ä¼˜å…ˆé€‰æ‹©
        relevant_edges.sort(key=lambda x: (x[1], x[2] == 'functional'), reverse=True)

        # è¿”å›è¾¹å¯¹è±¡åˆ—è¡¨
        return [edge for edge, _, _ in relevant_edges]
    
    def _relation_centric_sampling_with_anchors(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                               required_node_types: Set[NodeType]) -> List[SubgraphSample]:
        """ä¼˜åŒ–çš„å…³ç³»ä¸­å¿ƒé‡‡æ · - å¹¶è¡ŒåŒ–å¤„ç†"""
        subgraphs = []
        
        # 1. æ™ºèƒ½é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹
        target_nodes = self._find_smart_target_nodes(task_graph, seed, required_node_types)
        logger.debug(f"ğŸ¯ Found {len(target_nodes)} smart target nodes for relation-centric sampling")
        
        # 2. é™åˆ¶å¤„ç†æ•°é‡ï¼Œæé«˜æ•ˆç‡
        max_targets = min(len(target_nodes), 15)  # æœ€å¤šå¤„ç†15ä¸ªç›®æ ‡èŠ‚ç‚¹
        
        # 3. æ™ºèƒ½å¹¶å‘å¤„ç†ï¼šæ ¹æ®ç›®æ ‡èŠ‚ç‚¹æ•°é‡å†³å®šæ˜¯å¦ä½¿ç”¨å¹¶å‘
        if len(target_nodes) > 3 and self.config.enable_concurrency:
            # ä½¿ç”¨å—æ§çš„å¹¶å‘å¤„ç†ï¼Œé™åˆ¶çº¿ç¨‹æ•°
            subgraphs = self._controlled_parallel_relation_sampling(
                task_graph, target_nodes[:max_targets], seed, required_node_types
            )
        else:
            # ä¸²è¡Œå¤„ç†ï¼ˆç›®æ ‡èŠ‚ç‚¹å°‘æ—¶ï¼‰
            for target_node_id in target_nodes[:max_targets]:
                subgraph = self._optimized_backward_sampling(
                    task_graph, target_node_id, seed, required_node_types
                )
                
                if subgraph and self._validate_subgraph_with_anchors(subgraph, seed, required_node_types):
                    subgraphs.append(subgraph)
        
                    # é™åˆ¶å­å›¾æ•°é‡
                    if len(subgraphs) >= 15:
                        break
        
        logger.info(f"ğŸ¯ Relation-centric sampling completed: {len(subgraphs)} subgraphs for {seed.name}")
        return subgraphs
    
    def _find_smart_target_nodes(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                required_node_types: Set[NodeType]) -> List[str]:
        """æ™ºèƒ½é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹ - ä¼˜å…ˆé€‰æ‹©é«˜ä»·å€¼èŠ‚ç‚¹"""
        target_nodes = []
        
        # 1. ä¼˜å…ˆé€‰æ‹©åŒ…å«å¿…éœ€é”šç‚¹ç±»å‹çš„èŠ‚ç‚¹
        for node_id, node in task_graph.nodes.items():
            if node is None:
                continue
                
            if node.node_type in required_node_types:
                target_nodes.append(node_id)
        
        # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°é”šç‚¹èŠ‚ç‚¹ï¼Œé€‰æ‹©ç›¸å…³èŠ‚ç‚¹
        if not target_nodes:
            for node_id, node in task_graph.nodes.items():
                    
                if self._is_node_relevant_for_seed(node, seed):
                    target_nodes.append(node_id)
        
        # 3. æŒ‰é‡è¦æ€§æ’åº
        target_nodes.sort(key=lambda node_id: self._calculate_node_importance(
            task_graph.nodes[node_id], seed, required_node_types
        ), reverse=True)
        
        return target_nodes
    
    def _calculate_node_importance(self, node: Any, seed: TaskSeedPattern, 
                                  required_node_types: Set[NodeType]) -> float:
        """è®¡ç®—èŠ‚ç‚¹é‡è¦æ€§åˆ†æ•°"""
        if node is None:
            return 0.0
        score = 0.0
        
        # 1. é”šç‚¹ç±»å‹åŒ¹é…
        if node.node_type in required_node_types:
            score += 20.0
        
        # 2. ç§å­ç±»å‹åŒ¹é…
        if self._is_node_relevant_for_seed(node, seed):
            score += 10.0
        
        # 3. èŠ‚ç‚¹ç±»å‹é‡è¦æ€§
        importance_map = {
            'business_data': 15.0,
            'form': 12.0,
            'input': 10.0,
            'button': 8.0,
            'navigation': 8.0,
            'content': 6.0,
            'table': 6.0
        }
        
        node_type_lower = node.node_type.value.lower()
        score += importance_map.get(node_type_lower, 3.0)
        
        return score
    
    def _controlled_parallel_relation_sampling(self, task_graph: TaskGraph, target_nodes: List[str], 
                                             seed: TaskSeedPattern, required_node_types: Set[NodeType]) -> List[SubgraphSample]:
        """å—æ§çš„å¹¶è¡Œå…³ç³»é‡‡æ · - é™åˆ¶çº¿ç¨‹æ•°ï¼Œé¿å…èµ„æºç«äº‰"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        subgraphs = []
        
        # æ™ºèƒ½è®¡ç®—çº¿ç¨‹æ•°ï¼šç¡®ä¿æ€»çº¿ç¨‹æ•°ä¸è¶…è¿‡ç³»ç»Ÿé™åˆ¶
        import os
        cpu_count = os.cpu_count() or 4
        max_system_threads = cpu_count * 2  # ä¿å®ˆä¼°è®¡
        
        # è®¡ç®—å½“å‰å·²ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼ˆä¼°ç®—ï¼‰
        estimated_current_threads = self.config.max_workers  # ç¬¬ä¸€å±‚çº¿ç¨‹æ•°
        
        # ä¸ºç¬¬ä¸‰å±‚åˆ†é…å‰©ä½™çº¿ç¨‹æ•°
        available_threads = max(1, max_system_threads - estimated_current_threads)
        max_workers = min(len(target_nodes), available_threads, 3)  # æœ€å¤š3ä¸ªçº¿ç¨‹
        
        logger.debug(f"ğŸ¯ Controlled parallel relation sampling: {len(target_nodes)} targets, {max_workers} workers")
        
        with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="ControlledRelation") as executor:
            # æäº¤ä»»åŠ¡
            future_to_node = {}
            for target_node_id in target_nodes:
                future = executor.submit(
                    self._optimized_backward_sampling,
                    task_graph, target_node_id, seed, required_node_types
                )
                future_to_node[future] = target_node_id
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_node):
                target_node_id = future_to_node[future]
                try:
                    subgraph = future.result()
                    if subgraph and self._validate_subgraph_with_anchors(subgraph, seed, required_node_types):
                        subgraphs.append(subgraph)
                        logger.debug(f"ğŸ¯ Controlled parallel sampling: added subgraph from {target_node_id}")
                        
                        # é™åˆ¶å­å›¾æ•°é‡
                        if len(subgraphs) >= 15:
                            break
                except Exception as e:
                    logger.warning(f"ğŸ¯ Controlled parallel sampling failed for {target_node_id}: {e}")
        
        return subgraphs
    
    def _controlled_strategy_execution(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                     required_node_types: Set[NodeType], 
                                     recommended_strategies: List[SamplingStrategy]) -> List[SubgraphSample]:
        """å—æ§çš„ç­–ç•¥çº§å¹¶å‘æ‰§è¡Œ - é™åˆ¶çº¿ç¨‹æ•°ï¼Œé¿å…èµ„æºç«äº‰"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        strategy_subgraphs = []
        
        # æ™ºèƒ½è®¡ç®—çº¿ç¨‹æ•°ï¼šç¡®ä¿æ€»çº¿ç¨‹æ•°ä¸è¶…è¿‡ç³»ç»Ÿé™åˆ¶
        import os
        cpu_count = os.cpu_count() or 4
        max_system_threads = cpu_count * 2  # ä¿å®ˆä¼°è®¡
        
        # è®¡ç®—å½“å‰å·²ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼ˆä¼°ç®—ï¼‰
        estimated_current_threads = self.config.max_workers  # ç¬¬ä¸€å±‚çº¿ç¨‹æ•°
        
        # ä¸ºç¬¬äºŒå±‚åˆ†é…å‰©ä½™çº¿ç¨‹æ•°
        available_threads = max(1, max_system_threads - estimated_current_threads)
        max_workers = min(len(recommended_strategies), available_threads, 2)  # æœ€å¤š2ä¸ªç­–ç•¥å¹¶å‘
        
        logger.debug(f"ğŸ¯ Controlled strategy execution: {len(recommended_strategies)} strategies, {max_workers} workers")
        
        with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="ControlledStrategy") as executor:
            # æäº¤ç­–ç•¥ä»»åŠ¡
            future_to_strategy = {}
            for strategy in recommended_strategies:
                future = executor.submit(
                    self._execute_single_strategy,
                    task_graph, seed, required_node_types, strategy
                )
                future_to_strategy[future] = strategy
            
            # æ”¶é›†ç­–ç•¥ç»“æœ
            for future in as_completed(future_to_strategy):
                strategy = future_to_strategy[future]
                try:
                    strategy_result = future.result()
                    strategy_subgraphs.extend(strategy_result)
                    logger.debug(f"ğŸ¯ Controlled strategy {strategy.value} completed: {len(strategy_result)} subgraphs")
                except Exception as e:
                    logger.error(f"ğŸ¯ Controlled strategy {strategy.value} failed: {e}")
        
        return strategy_subgraphs
    
    def _optimized_backward_sampling(self, task_graph: TaskGraph, target_node_id: str, 
                                   seed: TaskSeedPattern, required_node_types: Set[NodeType]) -> Optional[SubgraphSample]:
        """ä¼˜åŒ–çš„åå‘é‡‡æ · - æ›´æ™ºèƒ½çš„æ‰©å±•ç­–ç•¥"""
        sampled_nodes = {target_node_id: task_graph.nodes[target_node_id]}
        sampled_edges = {}
        queue = deque([target_node_id])
        visited = {target_node_id}
        
        # é™åˆ¶é‡‡æ ·å‚æ•°
        max_depth = 4
        max_nodes = self.config.max_nodes
        current_depth = 0
        
        while queue and len(sampled_nodes) < max_nodes and current_depth < max_depth:
            current_level_size = len(queue)
            current_depth += 1
            
            for _ in range(current_level_size):
                if not queue:
                    break
                    
                current_node_id = queue.popleft()
                
                # æ™ºèƒ½åå‘æ‰©å±•
                relevant_edges = self._find_backward_edges(
                    task_graph, current_node_id, seed, required_node_types
                )
                
                for edge in relevant_edges[:4]:  # é™åˆ¶æ¯ä¸ªèŠ‚ç‚¹çš„æ‰©å±•æ•°é‡
                    neighbor_id = edge.source_node_id if edge.target_node_id == current_node_id else edge.target_node_id
                    
                    if neighbor_id not in visited and len(sampled_nodes) < max_nodes:
                        visited.add(neighbor_id)
                        sampled_nodes[neighbor_id] = task_graph.nodes[neighbor_id]
                        sampled_edges[edge.edge_id] = edge
                        queue.append(neighbor_id)
        
        # ç¡®ä¿åŒ…å«å¿…éœ€çš„é”šç‚¹
        self._ensure_anchor_nodes_present(task_graph, sampled_nodes, sampled_edges, required_node_types)

        # ç¡®ä¿å­å›¾çš„å¯è¾¾æ€§ï¼Œç§»é™¤ä¸å¯è¾¾çš„èŠ‚ç‚¹
        if not self._ensure_subgraph_reachability(sampled_nodes, sampled_edges):
            logger.debug(f"ğŸ¯ Failed to ensure subgraph reachability for target node {target_node_id}")
            return None

        if len(sampled_nodes) >= 2:
            return SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=target_node_id,
                strategy=SamplingStrategy.RELATION_CENTRIC
            )
        
        return None
    
    def _find_backward_edges(self, task_graph: TaskGraph, node_id: str, 
                            seed: TaskSeedPattern, required_node_types: Set[NodeType]) -> List[Any]:
        """æ‰¾åˆ°åå‘ç›¸å…³çš„è¾¹"""
        relevant_edges = []
        
        for edge in task_graph.edges.values():
            if edge.target_node_id == node_id:  # åå‘è¾¹ï¼šæŒ‡å‘å½“å‰èŠ‚ç‚¹
                # ä¼˜å…ˆé€‰æ‹©åŠŸèƒ½æ€§è¾¹
                if edge.edge_type.value.lower() in ['controls', 'fills', 'opens', 'nav_to']:
                    relevant_edges.append(edge)
                elif edge.edge_type.value.lower() == 'contains':
                    relevant_edges.append(edge)
        
        # æŒ‰è¾¹ç±»å‹é‡è¦æ€§æ’åº
        edge_priority = {'controls': 4, 'fills': 4, 'opens': 3, 'nav_to': 3, 'contains': 2}
        relevant_edges.sort(key=lambda e: edge_priority.get(e.edge_type.value.lower(), 0), reverse=True)
        
        return relevant_edges
    
    
    
    def _functional_module_sampling(self, task_graph: TaskGraph, task_seeds: List[TaskSeedPattern]) -> List[SubgraphSample]:
        """åŠŸèƒ½æ¨¡å—å¯¼å‘é‡‡æ · - ç”Ÿæˆé€šç”¨çš„ã€å¯å¤ç”¨çš„å­å›¾"""
        subgraphs = []
        
        logger.info(f"ğŸ¯ Starting functional module sampling")
        
        # å®šä¹‰åŠŸèƒ½æ¨¡å—ç»„åˆ - è¿™äº›æ˜¯é€šç”¨çš„åŠŸèƒ½æ¨¡å¼
        functional_combinations = [
            # æœç´¢åŠŸèƒ½ç»„åˆ
            {NodeType.SEARCH_BOX, NodeType.BUTTON, NodeType.RESULT_ITEM},
            # è¡¨å•åŠŸèƒ½ç»„åˆ
            {NodeType.FORM, NodeType.INPUT, NodeType.BUTTON},
            # å¯¼èˆªåŠŸèƒ½ç»„åˆ
            {NodeType.NAVIGATION, NodeType.LINK, NodeType.PAGE},
            # æ•°æ®å±•ç¤ºç»„åˆ
            {NodeType.TABLE, NodeType.BUSINESS_DATA, NodeType.BUTTON},
            # ç”¨æˆ·äº¤äº’ç»„åˆ
            {NodeType.USER_DATA, NodeType.BUTTON, NodeType.LINK},
            # äº§å“æµè§ˆç»„åˆ
            {NodeType.PRODUCT_DATA, NodeType.LINK, NodeType.BUTTON},
            # è®¢å•ç®¡ç†ç»„åˆ
            {NodeType.ORDER_DATA, NodeType.BUTTON, NodeType.TABLE}
        ]
        
        for combination in functional_combinations:
            # æ‰¾åˆ°åŒ…å«è¿™äº›åŠŸèƒ½æ¨¡å—çš„èŠ‚ç‚¹
            matching_nodes = []
            for node_id, node in task_graph.nodes.items():
                if node is None:
                    continue
                if node.node_type in combination:
                    matching_nodes.append(node_id)
            
            if len(matching_nodes) >= 2:  # è‡³å°‘éœ€è¦2ä¸ªåŠŸèƒ½æ¨¡å—
                # ä»è¿™äº›èŠ‚ç‚¹å¼€å§‹é‡‡æ ·ï¼Œä½†ä¸ç»‘å®šç‰¹å®šç§å­
                for start_node_id in matching_nodes[:3]:  # æœ€å¤šå°è¯•3ä¸ªèµ·å§‹èŠ‚ç‚¹
                    # ä½¿ç”¨é€šç”¨çš„BFSé‡‡æ ·ï¼Œä¸ç»‘å®šç§å­
                    subgraph = self._generic_bfs_sampling(task_graph, start_node_id)
                    if subgraph and self._validate_generic_subgraph(subgraph, combination):
                        subgraphs.append(subgraph)
                        logger.debug(f"ğŸ¯ Added generic functional module subgraph: {combination} -> {len(subgraph.nodes)} nodes")
                        break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªç»„åˆ
        
        logger.info(f"ğŸ¯ Functional module sampling generated {len(subgraphs)} generic subgraphs")
        return subgraphs
    
    def _generic_bfs_sampling(self, task_graph: TaskGraph, center_node_id: str) -> Optional[SubgraphSample]:
        """é€šç”¨çš„BFSé‡‡æ · - ä¸ç»‘å®šç‰¹å®šä»»åŠ¡ç§å­ï¼Œç”Ÿæˆå¯å¤ç”¨çš„å­å›¾"""
        sampled_nodes = {center_node_id: task_graph.nodes[center_node_id]}
        sampled_edges = {}
        
        # BFSæ‰©å±•ï¼Œä½†é™åˆ¶è·³æ•°å’Œç±»å‹
        queue = deque([(center_node_id, 0)])
        visited = {center_node_id}
        
        while queue and len(sampled_nodes) < self.config.max_nodes:
            current_node_id, distance = queue.popleft()
            
            # è·³æ•°é™åˆ¶ï¼šæœ€å¤š3è·³
            if distance >= 3:
                continue
            
            for edge in task_graph.edges.values():
                if edge.source_node_id == current_node_id and edge.target_node_id not in visited:
                    # é€šç”¨çš„è¾¹åŒ…å«é€»è¾‘ï¼Œä¸ä¾èµ–ç‰¹å®šç§å­
                    should_include_edge = self._should_include_edge_generic(edge, sampled_nodes)
                    
                    if should_include_edge:
                        sampled_edges[edge.edge_id] = edge
                        sampled_nodes[edge.target_node_id] = task_graph.nodes[edge.target_node_id]
                        visited.add(edge.target_node_id)
                        queue.append((edge.target_node_id, distance + 1))
                        
                        logger.debug(f"ğŸ¯ Generic BFS sampling: included edge {edge.edge_id} ({edge.edge_type}) to {edge.target_node_id}")
        
        if len(sampled_nodes) >= self.config.min_nodes:
            return SubgraphSample(
                nodes=sampled_nodes,
                edges=sampled_edges,
                center_node=center_node_id,
                radius=3,
                strategy=SamplingStrategy.FUNCTIONAL_MODULE,
                task_seed=None  # ä¸ç»‘å®šç‰¹å®šç§å­
            )
        
        return None
    
    def _should_include_edge_generic(self, edge, sampled_nodes: Dict[str, GraphNode]) -> bool:
        """é€šç”¨çš„è¾¹åŒ…å«åˆ¤æ–­é€»è¾‘ - ä¸ä¾èµ–ç‰¹å®šç§å­"""
        # 1. åŸºæœ¬çš„è¿æ¥æ€§æ£€æŸ¥
        if edge.source_node_id not in sampled_nodes:
            return False
        
        # 2. ä¼˜å…ˆåŒ…å«åŠŸèƒ½æ€§çš„è¾¹ç±»å‹
        functional_edge_types = {
            EdgeType.CONTROLS, EdgeType.NAV_TO, EdgeType.OPENS, 
            EdgeType.FILTERS, EdgeType.CONTAINS
        }
        
        if edge.edge_type in functional_edge_types:
            return True
        
        # 3. æ£€æŸ¥ç›®æ ‡èŠ‚ç‚¹æ˜¯å¦æ˜¯æœ‰ä»·å€¼çš„èŠ‚ç‚¹ç±»å‹
        target_node = edge.target_node_id
        if target_node in sampled_nodes:
            node = sampled_nodes[target_node]
            valuable_node_types = {
                NodeType.BUTTON, NodeType.LINK, NodeType.INPUT, 
                NodeType.SEARCH_BOX, NodeType.FORM, NodeType.TABLE,
                NodeType.BUSINESS_DATA, NodeType.USER_DATA, 
                NodeType.PRODUCT_DATA, NodeType.ORDER_DATA
            }
            if node.node_type in valuable_node_types:
                return True
        
        return False
    
    def _validate_generic_subgraph(self, subgraph: SubgraphSample, required_modules: Set[NodeType]) -> bool:
        """éªŒè¯é€šç”¨å­å›¾æ˜¯å¦æ»¡è¶³åŠŸèƒ½æ¨¡å—è¦æ±‚"""
        if not subgraph or len(subgraph.nodes) < self.config.min_nodes:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„åŠŸèƒ½æ¨¡å—
        subgraph_node_types = {node.node_type for node in subgraph.nodes.values() if node is not None}
        module_coverage = len(subgraph_node_types.intersection(required_modules))
        
        # è‡³å°‘éœ€è¦2ä¸ªåŠŸèƒ½æ¨¡å—
        if module_coverage < 2:
            return False
        
        # æ£€æŸ¥è¿æ¥æ€§
        if not self._validate_subgraph_connectivity(subgraph.nodes, subgraph.edges):
            return False
        
        logger.debug(f"ğŸ¯ Generic subgraph validation passed: {module_coverage} modules covered")
        return True
    
    # ==================== åˆ é™¤ï¼šå¹¶å‘BFSé‡‡æ ·ï¼ˆä¸å†éœ€è¦ï¼‰====================
    # å¹¶å‘BFSé‡‡æ ·å·²è¢«åˆ é™¤ï¼Œå› ä¸ºï¼š
    # 1. ä¼šå¯¼è‡´åµŒå¥—å¹¶å‘é—®é¢˜
    # 2. å¢åŠ äº†çº¿ç¨‹/è¿›ç¨‹å¼€é”€
    # 3. BFSéå†æœ¬èº«æ˜¯é¡ºåºçš„ï¼Œå¼ºåˆ¶å¹¶å‘æ²¡æœ‰æ„ä¹‰
    
    # ==================== ä¸²è¡Œå¤„ç†ï¼ˆå‘åå…¼å®¹ï¼‰ ====================
    
    def _sequential_seed_processing(self, task_graph: TaskGraph, task_seeds: List[TaskSeedPattern]) -> List[SubgraphSample]:
        """ä¸²è¡Œå¤„ç†ç§å­ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        subgraphs = []
        
        for seed in task_seeds:
            logger.info(f"ğŸ¯ Processing seed: {seed.name} (type: {seed.seed_type.value})")
            
            # ç¡®å®šç§å­å¿…éœ€çš„èŠ‚ç‚¹ç±»å‹ï¼ˆé”šç‚¹ï¼‰
            required_node_types = self._get_seed_anchor_nodes(seed)
            logger.debug(f"ğŸ¯ Seed {seed.name} requires anchor nodes: {required_node_types}")
            
            # é€‰æ‹©æœ€é€‚åˆçš„é‡‡æ ·ç­–ç•¥
            recommended_strategies = self._get_recommended_strategies_for_seed(seed)
            logger.debug(f"ğŸ¯ Recommended strategies for {seed.name}: {[s.value for s in recommended_strategies]}")
            
            # æ‰§è¡Œå¼ºç»‘å®šé‡‡æ ·
            seed_subgraphs = self._execute_seed_bound_sampling(
                task_graph, seed, required_node_types, recommended_strategies
            )
            
            subgraphs.extend(seed_subgraphs)
            logger.info(f"ğŸ¯ Generated {len(seed_subgraphs)} subgraphs for seed {seed.name}")
        
        return subgraphs
    
    # ==================== å¹¶å‘æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜ ====================
    
    def monitor_concurrency_performance(self, start_time: float, task_seeds_count: int, 
                                      subgraphs_count: int) -> Dict[str, Any]:
        """ç›‘æ§å¹¶å‘æ€§èƒ½æŒ‡æ ‡"""
        elapsed_time = time.time() - start_time
        seeds_per_second = task_seeds_count / elapsed_time if elapsed_time > 0 else 0
        subgraphs_per_second = subgraphs_count / elapsed_time if elapsed_time > 0 else 0
        
        performance_metrics = {
            "total_time": elapsed_time,
            "seeds_processed": task_seeds_count,
            "subgraphs_generated": subgraphs_count,
            "seeds_per_second": seeds_per_second,
            "subgraphs_per_second": subgraphs_per_second,
            "concurrency_enabled": self.config.enable_concurrency,
            "max_workers": self.config.max_workers,
            "chunk_size": self.config.chunk_size
        }
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        logger.info(f"ğŸ¯ Performance Metrics:")
        logger.info(f"  - Total time: {elapsed_time:.2f}s")
        logger.info(f"  - Seeds processed: {task_seeds_count}")
        logger.info(f"  - Subgraphs generated: {subgraphs_count}")
        logger.info(f"  - Throughput: {seeds_per_second:.2f} seeds/s, {subgraphs_per_second:.2f} subgraphs/s")
        
        return performance_metrics
    
    
    def _execute_single_strategy(self, task_graph: TaskGraph, seed: TaskSeedPattern, 
                                required_node_types: Set[NodeType], strategy: SamplingStrategy) -> List[SubgraphSample]:
        """æ‰§è¡Œå•ä¸ªé‡‡æ ·ç­–ç•¥ - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            if strategy == SamplingStrategy.ELEMENT_CENTRIC:
                return self._simple_element_centric_sampling(task_graph, seed)
            elif strategy == SamplingStrategy.GOAL_CONDITIONED:
                return self._simple_goal_conditioned_sampling(task_graph, seed)
            elif strategy == SamplingStrategy.RELATION_CENTRIC:
                return self._simple_relation_centric_sampling(task_graph, seed)
            elif strategy == SamplingStrategy.FUNCTIONAL_MODULE:
                return self._functional_module_sampling(task_graph, [seed])
            else:
                # é»˜è®¤ä½¿ç”¨å…ƒç´ ä¸­å¿ƒé‡‡æ ·
                return self._simple_element_centric_sampling(task_graph, seed)
        except Exception as e:
            logger.error(f"ğŸ¯ Strategy {strategy.value} execution failed: {e}")
            return []
    
    
    def update_concurrency_config(self, **kwargs):
        """åŠ¨æ€æ›´æ–°å¹¶å‘é…ç½®"""
        with self._lock:
            for key, value in kwargs.items():
                if hasattr(self.config, key):
                    setattr(self.config, key, value)
                    logger.info(f"ğŸ¯ Updated concurrency config: {key} = {value}")
            
            # é‡æ–°åˆå§‹åŒ–æ‰§è¡Œå™¨
            if self.executor:
                self.executor.shutdown(wait=True)
            self._init_executor()
    
    def get_concurrency_stats(self) -> Dict[str, Any]:
        """è·å–å¹¶å‘ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "enabled": self.config.enable_concurrency,
            "max_workers": self.config.max_workers,
            "chunk_size": self.config.chunk_size,
            "use_thread_pool": self.config.use_thread_pool,
            "executor_type": type(self.executor).__name__ if self.executor else "None"
        }
        
        if self.executor:
            if hasattr(self.executor, '_max_workers'):
                stats["active_workers"] = self.executor._max_workers
            if hasattr(self.executor, '_threads'):
                stats["thread_count"] = len(self.executor._threads)
        
        return stats
    
    def optimize_chunk_size(self, task_seeds_count: int) -> int:
        """æ™ºèƒ½ä¼˜åŒ–ä»»åŠ¡åˆ†å—å¤§å° - ä¿®å¤åçš„é€»è¾‘"""
        if task_seeds_count <= 4:
            return 1
        elif task_seeds_count <= 16:
            return 4  # å¢åŠ chunkå¤§å°ï¼Œå‡å°‘ä»»åŠ¡åˆ†ç‰‡
        elif task_seeds_count <= 64:
            return 8  # å¢åŠ chunkå¤§å°
        else:
            return min(12, task_seeds_count // 8)  # é™åˆ¶æœ€å¤§chunkå¤§å°
    
    
    def sample_subgraphs(self, task_graph: TaskGraph, task_seeds: List[TaskSeedPattern]) -> Tuple[List[SubgraphSample], List[Dict[str, Any]]]:
        """åŸºäºä»»åŠ¡ç§å­çš„å¼ºç»‘å®šå­å›¾é‡‡æ · - ä¿®å¤ååªä¿ç•™ç§å­çº§å¹¶å‘"""
        start_time = time.time()
        
        # è¿‡æ»¤æ‰ä¸éœ€è¦çš„ä¸šåŠ¡æ•°æ®ä»»åŠ¡ç§å­ï¼Œåªä¿ç•™å¯¼èˆªå’Œæœç´¢è¿‡æ»¤ä»»åŠ¡
        filtered_seeds = self._filter_allowed_seeds(task_seeds)
        
        logger.info(f"ğŸ¯ Starting simplified concurrent subgraph sampling with {len(filtered_seeds)} task seeds (filtered from {len(task_seeds)})")
        logger.info(f"ğŸ¯ Task graph has {len(task_graph.nodes)} nodes and {len(task_graph.edges)} edges")
        logger.info(f"ğŸ¯ Concurrency enabled: {self.config.enable_concurrency}, Workers: {self.config.max_workers}")
        logger.info(f"ğŸ¯ Config details: enable_concurrency={self.config.enable_concurrency}, use_thread_pool={self.config.use_thread_pool}, max_workers={self.config.max_workers}")
        logger.info(f"ğŸ¯ Executor type: {type(self.executor).__name__ if self.executor else 'None'}")
        
        # åˆ†æå›¾ç»“æ„
        self._analyze_graph_structure(task_graph)
        
        if self.config.enable_concurrency:
            logger.info(f"ğŸ¯ Using CONCURRENT processing with {self.config.max_workers} workers")
            # ä¿®å¤åï¼šåªä½¿ç”¨ç§å­çº§å¹¶å‘ï¼Œé¿å…åµŒå¥—å¹¶å‘é—®é¢˜
            subgraphs = self._concurrent_seed_processing_simple(task_graph, filtered_seeds)
        else:
            logger.info(f"ğŸ¯ Using SEQUENTIAL processing (concurrency disabled)")
            # ä¸²è¡Œå¤„ç†ç§å­ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            subgraphs = self._sequential_seed_processing(task_graph, filtered_seeds)
        
        # å¢å¼ºéªŒè¯å’Œå»é‡
        validated_subgraphs = self._enhanced_validation_and_deduplication(subgraphs)
        
        # æŒ‰å¯æ‰§è¡Œæ€§åˆ†æ•°æ’åº
        sorted_subgraphs = self._sort_by_executability_score(validated_subgraphs)
        
        # é™åˆ¶æ€»å­å›¾æ•°é‡
        if len(sorted_subgraphs) > self.config.max_total_subgraphs:
            logger.info(f"ğŸ¯ Limiting total subgraphs from {len(sorted_subgraphs)} to {self.config.max_total_subgraphs}")
            sorted_subgraphs = sorted_subgraphs[:self.config.max_total_subgraphs]
        
        # æ€§èƒ½ç›‘æ§
        performance_metrics = self.monitor_concurrency_performance(
            start_time, len(task_seeds), len(sorted_subgraphs)
        )
        
        # è½¬æ¢ä¸ºè¯¦ç»†çš„å­å›¾ä¿¡æ¯
        detailed_subgraphs = self._create_detailed_subgraphs(sorted_subgraphs)
        
        return sorted_subgraphs, detailed_subgraphs

    def _get_node_content(self, node) -> str:
        """è·å–èŠ‚ç‚¹çš„å†…å®¹ï¼Œæ”¯æŒä¸åŒç±»å‹çš„èŠ‚ç‚¹"""
        if not node:
            return ''

        # é¦–å…ˆå°è¯•è·å–èŠ‚ç‚¹çš„contentå±æ€§ï¼ˆç”¨äºä¼ ç»ŸNodeç±»å‹ï¼‰
        if hasattr(node, 'content') and node.content:
            content = str(node.content)
            return content[:100] + "..." if len(content) > 100 else content

        # å¯¹äºGraphNodeï¼Œå°è¯•ä»metadataä¸­è·å–text_content
        if hasattr(node, 'metadata') and node.metadata:
            text_content = getattr(node.metadata, 'text_content', '')
            if text_content:
                content = str(text_content)
                return content[:100] + "..." if len(content) > 100 else content

            # å¦‚æœæ²¡æœ‰text_contentï¼Œå°è¯•å…¶ä»–metadataå­—æ®µ
            placeholder = getattr(node.metadata, 'placeholder', '')
            if placeholder:
                content = str(placeholder)
                return content[:100] + "..." if len(content) > 100 else content

        # å¦‚æœéƒ½æ²¡æœ‰å†…å®¹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ''

    def _create_detailed_subgraphs(self, sorted_subgraphs: List[SubgraphSample]) -> List[Dict[str, Any]]:
        """è½¬æ¢ä¸ºè¯¦ç»†çš„å­å›¾ä¿¡æ¯ï¼Œä¾› benchmark_runner ä¿å­˜"""
        detailed_subgraphs = []
        for subgraph in sorted_subgraphs:
            detailed_info = {
                "subgraph_id": getattr(subgraph, 'subgraph_id', f"subgraph_{len(detailed_subgraphs)}"),
                "nodes": {node_id: {
                    "node_id": node_id,
                    "node_type": node.node_type.value if node and hasattr(node.node_type, 'value') else str(node.node_type) if node else "unknown",
                    "som_annotation": getattr(node, 'som_annotation', '') if node else '',
                    "content": self._get_node_content(node) if node else '',
                    "is_clickable": getattr(node, 'is_clickable', False) if node else False,
                    "is_input": getattr(node, 'is_input', False) if node else False,
                    "properties": getattr(node, 'properties', {}) if node else {}
                } for node_id, node in subgraph.nodes.items() if node is not None},
                "edges": {edge_id: {
                    "edge_id": edge_id,
                    "edge_type": edge.edge_type.value if edge and hasattr(edge.edge_type, 'value') else str(edge.edge_type) if edge else "unknown",
                    "source": edge.source_node_id if edge else "unknown",
                    "target": edge.target_node_id if edge else "unknown",
                    "properties": getattr(edge, 'properties', {}) if edge else {}
                } for edge_id, edge in subgraph.edges.items() if edge is not None},
                "sampling_strategy": getattr(subgraph, 'strategy', 'unknown').value if hasattr(getattr(subgraph, 'strategy', 'unknown'), 'value') else str(getattr(subgraph, 'strategy', 'unknown')),
                "seed_pattern": subgraph.task_seed.name if subgraph.task_seed else "unknown",
                "executability_score": getattr(subgraph, 'executability_score', 0.0),
                "center_node": getattr(subgraph, 'center_node', 'unknown'),
                "radius": getattr(subgraph, 'radius', 0),
                "node_count": len(subgraph.nodes),
                "edge_count": len(subgraph.edges)
            }
            detailed_subgraphs.append(detailed_info)
        
        return detailed_subgraphs
    
    def _concurrent_seed_processing_simple(self, task_graph: TaskGraph, task_seeds: List[TaskSeedPattern]) -> List[SubgraphSample]:
        """ä¿®å¤åçš„ç®€åŒ–ç§å­çº§å¹¶å‘å¤„ç† - é¿å…åµŒå¥—å¹¶å‘å’Œå†…å­˜å…±äº«é—®é¢˜"""
        all_subgraphs = []
        
        # æ™ºèƒ½è°ƒæ•´chunkå¤§å°ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å¹¶å‘
        if len(task_seeds) <= self.config.max_workers:
            # å¦‚æœç§å­æ•°é‡å°‘äºworkeræ•°é‡ï¼Œæ¯ä¸ªç§å­ä¸€ä¸ªchunk
            chunk_size = 1
        else:
            # å¦åˆ™ä½¿ç”¨é…ç½®çš„chunkå¤§å°ï¼Œä½†ç¡®ä¿è‡³å°‘æœ‰2ä¸ªchunk
            chunk_size = max(1, min(self.config.chunk_size, len(task_seeds) // 2))
        
        # å°†ç§å­åˆ†å—
        seed_chunks = [task_seeds[i:i + chunk_size] 
                      for i in range(0, len(task_seeds), chunk_size)]
        
        logger.info(f"ğŸ¯ Processing {len(task_seeds)} seeds in {len(seed_chunks)} chunks (chunk_size: {chunk_size})")
        logger.info(f"ğŸ¯ Using {self.config.max_workers} workers for concurrent processing")
        
        # æäº¤ç§å­å—ä»»åŠ¡ - æ¯ä¸ªchunkç‹¬ç«‹å¤„ç†ï¼Œé¿å…åµŒå¥—å¹¶å‘
        future_to_chunk = {}
        logger.info(f"ğŸ¯ Submitting {len(seed_chunks)} chunks to thread pool executor...")
        for chunk_idx, seed_chunk in enumerate(seed_chunks):
            logger.debug(f"ğŸ¯ Submitting chunk {chunk_idx} with {len(seed_chunk)} seeds")
            future = self.executor.submit(
                self._process_seed_chunk_simple, task_graph, seed_chunk, chunk_idx
            )
            future_to_chunk[future] = chunk_idx
            logger.debug(f"ğŸ¯ Chunk {chunk_idx} submitted to executor")
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_chunk):
            chunk_idx = future_to_chunk[future]
            try:
                chunk_subgraphs = future.result()
                all_subgraphs.extend(chunk_subgraphs)
                logger.info(f"ğŸ¯ Chunk {chunk_idx} completed: {len(chunk_subgraphs)} subgraphs")
            except Exception as e:
                logger.error(f"ğŸ¯ Chunk {chunk_idx} failed: {e}")
        
        logger.info(f"ğŸ¯ Simplified concurrent seed processing completed: {len(all_subgraphs)} total subgraphs")
        return all_subgraphs
    
    def _process_seed_chunk_simple(self, task_graph: TaskGraph, seed_chunk: List[TaskSeedPattern], chunk_idx: int) -> List[SubgraphSample]:
        """å¤„ç†ç§å­å— - ä¿®å¤åä¸²è¡Œå¤„ç†ï¼Œé¿å…åµŒå¥—å¹¶å‘"""
        chunk_subgraphs = []
        
        # æ·»åŠ çº¿ç¨‹ä¿¡æ¯ï¼ŒéªŒè¯å¹¶å‘æ‰§è¡Œ
        import threading
        thread_name = threading.current_thread().name
        logger.info(f"ğŸ¯ Chunk {chunk_idx} started processing in thread: {thread_name}")
        
        for seed in seed_chunk:
            logger.debug(f"ğŸ¯ Processing seed {seed.name} in chunk {chunk_idx} (thread: {thread_name})")
            
            # è®°å½•å¤„ç†è¿™ä¸ªç§å­ä¹‹å‰çš„å­å›¾æ•°é‡
            seed_start_count = len(chunk_subgraphs)
            
            # ç¡®å®šç§å­å¿…éœ€çš„èŠ‚ç‚¹ç±»å‹ï¼ˆé”šç‚¹ï¼‰
            required_node_types = self._get_seed_anchor_nodes(seed)
            
            # é€‰æ‹©æœ€é€‚åˆçš„é‡‡æ ·ç­–ç•¥
            recommended_strategies = self._get_recommended_strategies_for_seed(seed)
            
            # æ™ºèƒ½ç­–ç•¥çº§å¹¶å‘ï¼šæ ¹æ®ç­–ç•¥å¤æ‚åº¦å’Œæ•°é‡å†³å®šæ˜¯å¦ä½¿ç”¨å¹¶å‘
            if len(recommended_strategies) > 2 and self.config.enable_concurrency:
                # ä½¿ç”¨å—æ§çš„ç­–ç•¥çº§å¹¶å‘
                seed_subgraphs = self._controlled_strategy_execution(
                    task_graph, seed, required_node_types, recommended_strategies
                )
                # é™åˆ¶æ¯ä¸ªç§å­ç”Ÿæˆçš„å­å›¾æ•°é‡
                if len(seed_subgraphs) > self.config.max_subgraphs_per_seed:
                    logger.debug(f"ğŸ¯ Limiting seed {seed.name} subgraphs from {len(seed_subgraphs)} to {self.config.max_subgraphs_per_seed}")
                    seed_subgraphs = seed_subgraphs[:self.config.max_subgraphs_per_seed]
                chunk_subgraphs.extend(seed_subgraphs)
            else:
                # ä¸²è¡Œæ‰§è¡Œç­–ç•¥ï¼ˆç­–ç•¥å°‘æˆ–å¹¶å‘è¢«ç¦ç”¨æ—¶ï¼‰
                logger.debug(f"ğŸ¯ Using sequential strategy execution for seed {seed.name}")
                seed_subgraphs = []
                for strategy in recommended_strategies:
                    try:
                        strategy_result = self._execute_single_strategy(
                            task_graph, seed, required_node_types, strategy
                        )
                        seed_subgraphs.extend(strategy_result)
                        logger.debug(f"ğŸ¯ Strategy {strategy.value} completed: {len(strategy_result)} subgraphs")

                        # æ£€æŸ¥æ˜¯å¦å·²ç»è¾¾åˆ°ç§å­é™åˆ¶
                        if len(seed_subgraphs) >= self.config.max_subgraphs_per_seed:
                            logger.debug(f"ğŸ¯ Reached max subgraphs per seed limit ({self.config.max_subgraphs_per_seed}), stopping")
                            break
                    except Exception as e:
                        logger.error(f"ğŸ¯ Strategy {strategy.value} failed: {e}")
                        continue

                # æœ€ç»ˆé™åˆ¶æ¯ä¸ªç§å­çš„å­å›¾æ•°é‡
                if len(seed_subgraphs) > self.config.max_subgraphs_per_seed:
                    seed_subgraphs = seed_subgraphs[:self.config.max_subgraphs_per_seed]

                chunk_subgraphs.extend(seed_subgraphs)
            
            # è®¡ç®—è¿™ä¸ªç§å­å®é™…ç”Ÿæˆçš„å­å›¾æ•°é‡
            seed_generated_count = len(chunk_subgraphs) - seed_start_count
            logger.debug(f"ğŸ¯ Generated {seed_generated_count} subgraphs for seed {seed.name}")
        
        logger.info(f"ğŸ¯ Chunk {chunk_idx} completed in thread: {thread_name}, generated {len(chunk_subgraphs)} subgraphs")
        return chunk_subgraphs
    
    def _filter_allowed_seeds(self, task_seeds: List[TaskSeedPattern]) -> List[TaskSeedPattern]:
        """è¿‡æ»¤æ‰ä¸éœ€è¦çš„ä¸šåŠ¡æ•°æ®ä»»åŠ¡ç§å­ï¼Œåªä¿ç•™å¯¼èˆªå’Œæœç´¢è¿‡æ»¤ä»»åŠ¡"""
        # å®šä¹‰å…è®¸çš„ç§å­ç±»å‹ï¼ˆåªä¿ç•™å¯¼èˆªå’Œæœç´¢è¿‡æ»¤ä»»åŠ¡ï¼‰
        allowed_seed_types = {
            TaskSeedType.BUSINESS_SEARCH_FILTER,
            TaskSeedType.BUSINESS_NAVIGATION,
            TaskSeedType.USER_NAVIGATION,
            TaskSeedType.PRODUCT_NAVIGATION,
            TaskSeedType.ORDER_NAVIGATION,
            TaskSeedType.MIXED_DATA_NAVIGATION,
            TaskSeedType.MULTI_HOP_NAVIGATION,
            # ä¿ç•™æ‰€æœ‰äº¤äº’ç§å­
            TaskSeedType.CONTENT_BROWSING,
            TaskSeedType.BASIC_NAVIGATION,
            TaskSeedType.BUTTON_INTERACTION,
            TaskSeedType.MENU_EXPLORATION,
            TaskSeedType.TAB_SWITCHING,
            TaskSeedType.MODAL_INTERACTION,
            TaskSeedType.TOAST_NOTIFICATION,
            TaskSeedType.BREADCRUMB_NAVIGATION,
            TaskSeedType.PAGINATION_BROWSING,
            TaskSeedType.EXPAND_COLLAPSE,
            TaskSeedType.SCROLL_READING
        }
        
        # è¿‡æ»¤ç§å­
        filtered_seeds = []
        filtered_out_count = 0
        
        for seed in task_seeds:
            if seed.seed_type in allowed_seed_types:
                filtered_seeds.append(seed)
            else:
                filtered_out_count += 1
                logger.debug(f"ğŸ¯ Filtered out seed: {seed.name} (type: {seed.seed_type.value})")
        
        logger.info(f"ğŸ¯ Seed filtering: {len(filtered_seeds)} allowed, {filtered_out_count} filtered out")
        return filtered_seeds
